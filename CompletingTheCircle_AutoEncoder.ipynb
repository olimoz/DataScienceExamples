{
 "cells": [
  {
   "source": [
    "# Completing the Circle, A Language for Thinking\n",
    "\n",
    "### By Oliver Morris\n",
    "\n",
    "Are programming languages half way to useful AI? In object orientated programming we specify a class to represent the attributes and methods of an object, then create instances from the class. In other words we start with a specification and create examples. But our human experience is often the reverse. Typically we are presented with many examples and attempt to generalise them into classes. Having done so, we apply our classes to simplify our world, then revise our understanding as our specifications are challenged. So, is there a case for a programming language capable of both halves of this circle between examples and classes?\n",
    "\n",
    "Such a language could constantly adapt its classes to better meet some objective.\n",
    "\n",
    "The simplest deep learning model which approximates this circle is the autoencoder. An encoder takes instances and attempts to compress them into a latent space, this is analogous to extracting a class specification from examples. A decoder is required in order to train the encoder in a differentiable manner. Usually the latent space represents attributes of an object, but it could equally be tasked with finding the most concise specification of an action (class method), to meet some outcome.\n",
    "\n",
    "To repeat, the decoder is simply a differentiable manner of training the encoder. It would be preferable to use standard OOP to 'decode' the specification (latent space) into an instance. But such code would not be differentiable, requiring a reinforcement model as opposed to a straightforward neural network.\n",
    "\n",
    "## Line Autoencoder\n",
    "\n",
    "Let's take a simple example of this loop and explore how it might be built. Consider the drawing of a straight line, there's standard python code for that. But imagine if we had a model which could interpret such lines and arrange them into a new, more complex class. For example, shapes, or even a face. \n",
    "\n",
    "Trying to keep it simple, we would like to train an encoder which can deconstruct images of lines into their most compressed format, (start, end, width, colour etc). This is the latent space. We would lie to use the python line method, from the img class, as the decoder. That method reads the latent space (start, end, width, colour etc) and draws a line. This would then be compared with the image being entered to the encoder. A loss could be calculated and we'd proceed from there.\n",
    "\n",
    "As stated, we can't use the img.line method in the model's code, because its not differentiable. However we know the 'latent space' for specifying a line to be drawn by the img.line method (start, end, width, colour etc). We can generate examples of those specifications and the images which the method would have drawn using them. We can then train a decoder to do the same job as the img.line method. Having trained the decoder, we can train an encoder.\n",
    "\n",
    "## Long Term\n",
    "\n",
    "Ultimately, we'd like a deep reasoning tool, which can take instances then:\n",
    "\n",
    "    - hypothesise defining attributes (features)\n",
    "    - using layers of those features, reduce the instances to their useful essence (latent space)\n",
    "    - using that latent space, hypothesise a classification or rule about the object (not sure what the deep learning analogy is)\n",
    "    - test those rules against further examples and adjust accordingly (train)\n",
    "\n",
    "There are a large number of problems which fit this pattern. So let's explore how this toy problem yields to this approach."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data Generation\n",
    "\n",
    "Step 1 is to train a decoder using a latent space which is usable by the img.line method. Then we can train an encoder to match.\n",
    "The decoder will input line specifications and output images of lines, doing the same task the img.line method would.\n",
    "\n",
    "img.line uses the following inputs:\n",
    "('x_start', 'y_start'), ('x_end', 'y_end'), 'linecol', 'linewid', 'imgcolr'\n",
    "\n",
    "We'll need some images of lines from which to train the decoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTS\n",
    "\n",
    "# file management\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# math\n",
    "import math  as math\n",
    "import numpy as np\n",
    "from random  import seed\n",
    "from random  import randint\n",
    "\n",
    "# data manipulation\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# ggplot in python, and matplot lib for some tasks\n",
    "import plotnine as p9\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# deep learning\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras           import Model\n",
    "from tensorflow.keras.layers    import Input, LeakyReLU, PReLU, Concatenate, Reshape, Flatten, Dense, Activation\n",
    "from tensorflow.keras.layers    import Conv2D, MaxPool2D, UpSampling2D, Dropout, BatchNormalization, Add, ReLU\n",
    "from tensorflow.keras.models    import load_model, save_model\n",
    "from tensorflow.keras.utils     import plot_model\n",
    "\n",
    "# image manipulation\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file location\n",
    "proj_root  = 'D:\\\\Data\\\\ImageConcepts'\n",
    "subfolders = ['Lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tensorflow Version: 2.1.0\nIs tensorflow executing eagerly?  True\nIs tensorflow using GPU?  True\nIs tensorflow using Cuda?  True\n"
    }
   ],
   "source": [
    "#### Confirm environment\n",
    "\n",
    "print(\"Tensorflow Version:\",               tf.__version__)\n",
    "print(\"Is tensorflow executing eagerly? \", tf.executing_eagerly())\n",
    "print(\"Is tensorflow using GPU? \",         tf.test.is_built_with_gpu_support())\n",
    "print(\"Is tensorflow using Cuda? \",        tf.test.is_built_with_cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Images of Lines ###\n",
    "\n",
    "# We will need a function to add noise to the images of lines\n",
    "# else the model can only handle perfect situations\n",
    "\n",
    "def add_noise(img, var, w, h):\n",
    "    \n",
    "    # need to work in numpy format\n",
    "    img = np.array(img)\n",
    "\n",
    "    # set params for noise\n",
    "    mean= 0\n",
    "    sd  = var ** 0.5 \n",
    "\n",
    "    # create noise\n",
    "    noise = np.random.normal(loc=mean, scale=sd, size=(w, h)) #  np.zeros((w, h), np.float32)\n",
    "    noisy_image = np.zeros(img.shape, np.float32)\n",
    "\n",
    "    # apply noise\n",
    "    if len(img.shape) == 2:\n",
    "        # BW\n",
    "        noisy_image = img + noise\n",
    "    else:\n",
    "        # RGB\n",
    "        noisy_image[:, :, 0] = img[:, :, 0] + noise\n",
    "        noisy_image[:, :, 1] = img[:, :, 1] + noise\n",
    "        noisy_image[:, :, 2] = img[:, :, 2] + noise\n",
    "\n",
    "    cv2.normalize(noisy_image, noisy_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
    "\n",
    "    # format conversion\n",
    "    # first round the values to integers by simply changing dtype\n",
    "    noisy_img_npy = noisy_image.astype(np.uint8) \n",
    "    # those values can now be saved as an actual image\n",
    "    noisy_img_pil = Image.fromarray(noisy_image.astype(np.uint8))\n",
    "    # finally we need the integers in float format for Tensorflow\n",
    "    noisy_img_npy = noisy_img_npy.astype(np.float)\n",
    "\n",
    "    return noisy_img_pil, noisy_img_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TRAINING DATA. IMAGES OF LINES\n",
    "\n",
    "# seed random number generator\n",
    "seed(28042020)\n",
    "\n",
    "shape_list= []\n",
    "w, h = 64, 64\n",
    "\n",
    "for i in range(0,10000):\n",
    "\n",
    "    # get image params\n",
    "    x_start = randint(0, w)\n",
    "    y_start = randint(0, h)\n",
    "    x_end   = randint(0, w)\n",
    "    y_end   = randint(0, h)\n",
    "    linecol = randint(0, 255)\n",
    "    linewid = randint(1, 10)\n",
    "    imgcolr = randint(0, 255)\n",
    "    # we could use arcs instead of straight lines....\n",
    "    # angstrt = randint(0, 10) # arc start angle, in degs\n",
    "    # angends = randint(0, 10) # arc end angle, in degs\n",
    "\n",
    "    # instantiate image\n",
    "    # mode L is 8bit Greyscale\n",
    "    # other modes at: https://pillow.readthedocs.io/en/stable/handbook/concepts.html#concept-modes\n",
    "    img  = Image.new(mode='L', size=(w, h), color=imgcolr) \n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # add line(s)\n",
    "    shape = [(x_start, y_start), (x_end, y_end)] \n",
    "    draw.line(shape, fill=linecol, width=linewid) \n",
    "\n",
    "    # keep copy of clean image, no noise\n",
    "    img_npy = np.array(img)\n",
    "\n",
    "    # add random amount of noise to image\n",
    "    var = np.random.normal(loc=0, scale=1, size=2) # loc=mean, scale=sd, size=height\n",
    "    var = abs(var[0]) #+ve numbers only please.\n",
    "    img_noisy_pil, img_noisy_npy = add_noise(img, var=var, w=w, h=h)\n",
    "\n",
    "    # save to file\n",
    "    filename = str(i).rjust(5, '0') + '.png'\n",
    "    img_noisy_pil.save(os.path.join(proj_root, *subfolders, filename),\"PNG\")\n",
    "\n",
    "    # we could use just one number to reference the start point \n",
    "    # and another number to represent the end point. \n",
    "    # This is done by imaging the pixels are each addresses with a single number, \n",
    "    # starting at 1,1, for the top left of the image\n",
    "    # Therefore, two numbers are sufficient to record the start+end of the line.\n",
    "    # Autoencoders are compression algorithms, so can seek the simplest representation\n",
    "    get_pixel = lambda x,y,w,h : x+y*w\n",
    "    pix_start = get_pixel(x_start, y_start, w, h)\n",
    "    pix_end   = get_pixel(x_end,   y_end,   w, h)\n",
    "\n",
    "    # save ALL line details to list\n",
    "    shape_list.append(\n",
    "        # filename    + x,y start      + x,y end\n",
    "        [filename]    + list(shape[0]) + list(shape[1]) + \n",
    "        # pixel start + pixel end\n",
    "        [pix_start]   + [pix_end]  +\n",
    "        # line colour + line width + image colour\n",
    "        [linecol]     + [linewid]  + [imgcolr] + \n",
    "        # npy version of image (with noise), numpy version of image (no noise)\n",
    "        [img_noisy_npy] + [img_npy]\n",
    "        )\n",
    "\n",
    "# convert list of lists to pandas dataframe for convenience\n",
    "# first 4 columns are easy....\n",
    "shape_list_pd = pd.DataFrame(data   = [col[0:10] for col in shape_list], \n",
    "                             columns= ['filename', 'x_start', 'y_start', 'x_end', 'y_end', 'pix_start', 'pix_end', 'linecol', 'linewid', 'imgcolr'])\n",
    "\n",
    "# final columns, the numpy arrays, are awkward due type conversion\n",
    "shape_list_pd['img_noisy_npy'] = None\n",
    "shape_list_pd['img_noisy_npy'] = shape_list_pd['img_noisy_npy'].astype('object')\n",
    "shape_list_pd['img_noisy_npy'] = [col[10] for col in shape_list]\n",
    "\n",
    "shape_list_pd['img_npy'] = None\n",
    "shape_list_pd['img_npy'] = shape_list_pd['img_npy'].astype('object')\n",
    "shape_list_pd['img_npy'] = [col[11] for col in shape_list]\n",
    "\n",
    "# save data\n",
    "# We'd like to use panda's to_csv()\n",
    "# But, it adds '\\n' into every row of the numpy arrays\n",
    "# so we'll pickle the pandas object instead\n",
    "shape_list_pd.to_pickle(os.path.join(proj_root, *subfolders, 'lineslist.pkl'))\n",
    "\n",
    "# perhaps its useful to inspect the file, so let's save as csv as well...\n",
    "shape_list_pd.to_csv(os.path.join(proj_root, *subfolders, 'lineslist.csv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS TO SELECT TRAIN, TEST AND VALIDATION DATASETS\n",
    "\n",
    "# Load image data into training and testing data sets\n",
    "shape_list_pd = pd.read_pickle(os.path.join(proj_root, *subfolders, 'lineslist.pkl'))\n",
    "\n",
    "# proportions of data destined for train, test, validation\n",
    "propns = [0.9,0.09,0.01]\n",
    "rand_seqnc = np.random.rand(len(shape_list_pd))\n",
    "\n",
    "train_mask = rand_seqnc < propns[0]\n",
    "testi_mask = [True if rand > propns[0] and rand < (propns[0] + propns[1]) else False for rand in rand_seqnc]\n",
    "valid_mask = rand_seqnc > (propns[0]+propns[1])\n",
    "\n",
    "# prepare to standardise the data for the sake of better neural network weights\n",
    "# For this we need mean and sd of the image data:\n",
    "img_noisy_npy = np.stack(shape_list_pd['img_noisy_npy'], axis=0)\n",
    "\n",
    "mn_img = np.mean(img_noisy_npy)\n",
    "sd_img = np.std(img_noisy_npy)\n",
    "\n",
    "# As an alternative to standardising the data we may range_shift it\n",
    "# This requries us to have the min and range\n",
    "\n",
    "mins_img  = 0   # min is zero for images\n",
    "pk2pk_img = 255 # range is 0 to 255 for images\n",
    "\n",
    "del img_noisy_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and mean and sd of the latents (line specification)\n",
    "# Get y (latent space) targets in numpy format\n",
    "def get_latent_tgt(df):\n",
    "    y_latent = df[['x_start', 'y_start', 'x_end', 'y_end', 'linecol', 'linewid', 'imgcolr']]\n",
    "    y_latent = y_latent.to_numpy().astype('float32')\n",
    "    return y_latent\n",
    "\n",
    "latents_npy = get_latent_tgt(shape_list_pd)\n",
    "\n",
    "mn_ltn = np.mean(latents_npy, axis=0)\n",
    "sd_ltn = np.std(latents_npy, axis=0)\n",
    "\n",
    "# As an alternative to standardising the data we may range_shift it\n",
    "# This requries us to have the min and range\n",
    "mins_ltn  = 0   # min is zero for all fields\n",
    "pk2pk_ltn = np.ptp(latents_npy, axis=0) # range is different for all fields\n",
    "\n",
    "# delete memory hungry dataframes..\n",
    "del latents_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR STANDARDISING DATA\n",
    "\n",
    "def standardise(array_np, mn, sd):\n",
    "    # ensure mn and sd are in numpy array format\n",
    "    mn = mn if type(mn)==np.array else np.array([mn])\n",
    "    sd = sd if type(sd)==np.array else np.array([sd])\n",
    "\n",
    "    # standardise\n",
    "    array_np = (array_np - mn) / sd\n",
    "\n",
    "    return array_np\n",
    "\n",
    "def de_standardise(array_np, mn, sd):\n",
    "    # ensure mn and sd are in numpy array format\n",
    "    mn = mn if type(mn)==np.array else np.array([mn])\n",
    "    sd = sd if type(sd)==np.array else np.array([sd])\n",
    "\n",
    "    # reverse standardisation\n",
    "    array_np = (array_np * sd) + mn\n",
    "\n",
    "    # if array is an image, eg stack of numpy arrays,\n",
    "    # then convert to uint8, else leave as float32\n",
    "    if len(array_np.shape) > 2:\n",
    "        array_np = array_np.astype(np.uint8)\n",
    "\n",
    "    return array_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative to standardising the data is to shift the data into the range 0 to 1, or, -1 to 1\n",
    "# Best for use with sigmoid or tanh activation respectively\n",
    "\n",
    "def range_shift(array_np, mins=None, pk2pk=None):\n",
    "\n",
    "    # handle zero length array\n",
    "    if array_np.shape[0] == 0:\n",
    "        mins  = np.array([])\n",
    "        pk2pk = np.array([])\n",
    "\n",
    "    else:\n",
    "        array_np = (array_np - mins) / pk2pk\n",
    "\n",
    "    return array_np\n",
    "\n",
    "def de_range_shift(array_np, mins=None, pk2pk=None):\n",
    "\n",
    "    # handle zero length array\n",
    "    if array_np.shape[0] == 0:\n",
    "        mins  = np.array([])\n",
    "        pk2pk = np.array([])\n",
    "\n",
    "    else:      \n",
    "        array_np = (array_np * pk2pk) + mins\n",
    "\n",
    "    return array_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Whichever activation is used, we still need to shuffle the data\n",
    "# and get pandas file for train, test and validation\n",
    "\n",
    "def get_sample(shape_list_pd, mask, method):\n",
    "\n",
    "    assert method in ['standardise', 'range_shift'], 'ERROR: Data Processing Method Unknown'\n",
    "\n",
    "    # if mask is entirely false (propn = 0.0) then return blanks\n",
    "    if sum(mask) == 0:\n",
    "        subset_pd = shape_list_pd.head(0)\n",
    "        return subset_pd, np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    # filter samples using the mask, reset index\n",
    "    subset_pd = shape_list_pd[mask].reset_index(drop=True)\n",
    "\n",
    "    # The above line returns a pandas table but tensorflow will need\n",
    "    # numpy formatted data for the image arrays\n",
    "    # first we get the noisy version of the training data\n",
    "    ipt_noisy_np = subset_pd['img_noisy_npy']\n",
    "\n",
    "    # next we get the clean image\n",
    "    ipt_clean_np = subset_pd['img_npy']\n",
    "\n",
    "    # finally, the latents\n",
    "    ipt_latents  = get_latent_tgt(subset_pd)\n",
    "\n",
    "    # The image samples must be presented as a stack of numpy arrays\n",
    "    ipt_noisy_np = np.stack(ipt_noisy_np, axis=0)\n",
    "    ipt_clean_np = np.stack(ipt_clean_np, axis=0)\n",
    "    \n",
    "    # transform the data, for better neural net performance\n",
    "    if method == 'standardise':\n",
    "        ipt_noisy_np = standardise(ipt_noisy_np, mn=mn_img, sd=sd_img)\n",
    "        ipt_clean_np = standardise(ipt_clean_np, mn=mn_img, sd=sd_img)\n",
    "        ipt_latents  = standardise(ipt_latents,  mn=mn_ltn, sd=sd_ltn)\n",
    "    else : # must be range_shift\n",
    "        ipt_noisy_np = range_shift(ipt_noisy_np, mins=mins_img, pk2pk=pk2pk_img)\n",
    "        ipt_clean_np = range_shift(ipt_clean_np, mins=mins_img, pk2pk=pk2pk_img)\n",
    "        ipt_latents  = range_shift(ipt_latents,  mins=mins_ltn, pk2pk=pk2pk_ltn)\n",
    "\n",
    "    # Now we have dims = (samples, w, h). We need (samples, w, h, channels)\n",
    "    # Channels = 1 for BW images. For RGB images channels = 3\n",
    "    # then we need to use expand_dims to get channels = 1 (samples, w, h, channels)\n",
    "    ipt_noisy_np = np.expand_dims(ipt_noisy_np, axis=3)\n",
    "    ipt_clean_np = np.expand_dims(ipt_clean_np, axis=3)\n",
    "\n",
    "    return subset_pd, ipt_noisy_np, ipt_clean_np, ipt_latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Shape = (samples, w, h, channels)\nTrain\nNoisy image shape :  (90004, 64, 64, 1)\nClean image shape :  (90004, 64, 64, 1)\nLatents shape     :  (90004, 7)\n\n\nTest\nNoisy image shape :  (8956, 64, 64, 1)\nClean image shape :  (8956, 64, 64, 1)\nLatents shape     :  (8956, 7)\n\n\nValid\nNoisy image shape :  (1040, 64, 64, 1)\nClean image shape :  (1040, 64, 64, 1)\nLatents shape     :  (1040, 7)\n\n\n"
    }
   ],
   "source": [
    "### APPLY TRAINING SET FUNCTIONS\n",
    "\n",
    "# choose transform method\n",
    "method = 'range_shift' # choice is 'standardise', 'range_shift'\n",
    "\n",
    "train_pd, train_nsy, train_cln, train_ltn = get_sample(shape_list_pd, train_mask, method=method)\n",
    "testi_pd, testi_nsy, testi_cln, testi_ltn = get_sample(shape_list_pd, testi_mask, method=method)\n",
    "valid_pd, valid_nsy, valid_cln, valid_ltn = get_sample(shape_list_pd, valid_mask, method=method)\n",
    "\n",
    "# confirm correct shape: (samples, w, h, channels)\n",
    "def print_shapes(set_name, ipt, tgt, ltn):\n",
    "    print(set_name)\n",
    "    print('Noisy image shape : ', ipt.shape)\n",
    "    print('Clean image shape : ', tgt.shape)\n",
    "    print('Latents shape     : ', ltn.shape)\n",
    "    print('\\n')\n",
    "\n",
    "print('Shape = (samples, w, h, channels)')\n",
    "print_shapes('Train', train_nsy, train_cln, train_ltn)\n",
    "print_shapes('Test',  testi_nsy, testi_cln, testi_ltn)\n",
    "print_shapes('Valid', valid_nsy, valid_cln, valid_ltn) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODER MODEL BUILDING\n",
    "\n",
    "Although we will train the decoder first, separately to the encoder, we will specify the encoder first. This is simply because autoencoder's are traditionally built with encoder first. \n",
    "\n",
    "The architecture will be a fairly standard set of blocks. Each block comprised of Conv2D, BatchNorm, Skip layer, MaxPool. The skip layers connects each block to the input to the prior block. There will then be four dense layers which output into the latent space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder_line(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, params_dict, name, **kwargs):\n",
    "\n",
    "        super(encoder_line, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        # Get params\n",
    "        self.filters       = params_dict.get('filters')    # is list, not single item\n",
    "        self.dense_dims    = params_dict.get('dense_dims') # is list, not single item\n",
    "        self.kernel_size   = params_dict.get('kernel_size')\n",
    "        self.kinit         = params_dict.get('kinit')\n",
    "        self.leaky_alpha   = params_dict.get('leaky_alpha')\n",
    "        self.fnl_activation= params_dict.get('fnl_activation')\n",
    "\n",
    "        # Specify layers (channels last)\n",
    "        # Conv2D inputs  = (samples, rows, cols, channels)\n",
    "        # Conv2D outputs = (samples, new_rows, new_cols, filters)\n",
    "\n",
    "        # first conv block\n",
    "        self.conv1    = Conv2D(filters=self.filters[0], kernel_size=3, kernel_initializer=self.kinit, padding='same', activation=None)\n",
    "        self.batnm1   = BatchNormalization(axis=3)\n",
    "        # SKIP PATH. Bridge the MaxPool, similar to residual block\n",
    "        # feed original inputs to skip1. Hence filters =1, (no changes in channels) and strides = 2, so downsamples to same size as MaxPool\n",
    "        # this layer ensures same dims as outputs from pool1\n",
    "        self.skip1    = Conv2D(filters=1, kernel_size=1, strides=2, kernel_initializer=self.kinit, padding='same', activation=None)\n",
    "        self.conv1lky = PReLU(alpha_initializer='zeros')\n",
    "        self.pool1    = MaxPool2D((2,2))\n",
    "        \n",
    "        # next conv block\n",
    "        self.conv2    = Conv2D(filters=self.filters[1], kernel_size=3, kernel_initializer=self.kinit, padding='same', activation=None)\n",
    "        self.batnm2   = BatchNormalization(axis=3)\n",
    "        self.add1     = Add() #([x, skip1])\n",
    "        self.conv2lky = PReLU(alpha_initializer='zeros')\n",
    "        # SKIP PATH. Bridge the MaxPool, similar to residual block\n",
    "        # feed original inputs to skip1. Hence filters =1, (no changes in channels) and strides = 2, so downsamples to same size as MaxPool\n",
    "        # this layer ensures same dims as outputs from pool1\n",
    "        self.skip2    = Conv2D(filters=1, kernel_size=1, strides=2, kernel_initializer=self.kinit, padding='same', activation=None)\n",
    "        self.pool2    = MaxPool2D((2,2))\n",
    "\n",
    "        # next conv block\n",
    "        self.conv3    = Conv2D(filters=self.filters[2], kernel_size=3, kernel_initializer=self.kinit, padding='same', activation=None)\n",
    "        self.batnm3   = BatchNormalization(axis=3)\n",
    "        self.add2     = Add() #([x, skip2])\n",
    "        self.conv3lky = PReLU(alpha_initializer='zeros')\n",
    "        self.pool3    = MaxPool2D((2,2))\n",
    "        #self.dropout1 = Dropout(self.keep_propn)\n",
    "        self.flatten  = Flatten()\n",
    "\n",
    "        self.dense1   = Dense(self.dense_dims[0], kernel_initializer=self.kinit, activation=None)\n",
    "        self.dense1lky= PReLU(alpha_initializer='zeros')\n",
    "\n",
    "        self.dense2   = Dense(self.dense_dims[1], kernel_initializer=self.kinit, activation=None)\n",
    "        self.dense2lky= PReLU(alpha_initializer='zeros')\n",
    "\n",
    "        self.dense3   = Dense(self.dense_dims[2], kernel_initializer=self.kinit, activation=None)\n",
    "        self.dense3lky= PReLU(alpha_initializer='zeros')\n",
    "\n",
    "        self.dense4   = Dense(self.dense_dims[3], kernel_initializer=self.kinit, activation='linear')\n",
    "\n",
    "    # we need this in order to call model.summary()\n",
    "    # does not need to be a tf function\n",
    "    # @tf.function\n",
    "    def build_graph(self, input_shape): \n",
    "        input_shape_nobatch = input_shape[1:]\n",
    "        self.build(input_shape)\n",
    "        inputs = tf.keras.Input(shape=input_shape_nobatch)\n",
    " \n",
    "        if not hasattr(self, 'call'):\n",
    "            raise AttributeError(\"Must define 'call' method for class\")\n",
    "        \n",
    "        _ = self.call(inputs, training=True)\n",
    "\n",
    "    # make model serializable\n",
    "    def get_config(self):\n",
    "        return {'units': self.units}\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # Define forward pass here,\n",
    "        # 'training' is applicable to BatchNorm and DropOut\n",
    "        # eg self.dropout(x, training=training)\n",
    "        # keras.fit would normally do this, but we're using gradient tape\n",
    "        # Uses layers previously defined (in `__init__`).\n",
    "\n",
    "        # first conv block\n",
    "        x = self.conv1(inputs)\n",
    "        if training : x = self.batnm1(x)\n",
    "        x = self.conv1lky(x)\n",
    "        s = self.skip1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # next conv block\n",
    "        x = self.conv2(x)\n",
    "        if training : x = self.batnm2(x)\n",
    "        x = self.add1([x, s])\n",
    "        x = self.conv2lky(x)\n",
    "        s = self.skip2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # next conv block\n",
    "        x = self.conv3(x)\n",
    "        if training : x = self.batnm3(x)\n",
    "        x = self.add2([x, s])\n",
    "        x = self.conv3lky(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # logic blocks\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense1lky(x)\n",
    "\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense2lky(x)\n",
    "\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense3lky(x)\n",
    "\n",
    "        x = self.dense4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST ENCODER\n",
    "\n",
    "Latent space size: = 7. These are the features required to specify a line:\n",
    "    \n",
    "    pix_start_x, pix_start_y, \n",
    "    pix_end_x,   pix_end_y, \n",
    "    linewid, linecol, imgcol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Layer encoder_test is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nExpecting encoder output shape: (samples, latent_space_dims)\nActual encoder output shape   :   (5, 7)\n"
    }
   ],
   "source": [
    "latent_dims = 7\n",
    "\n",
    "# set params\n",
    "params_dict_enc =  { \n",
    "                'kernel_size'   : 3,\n",
    "                'filters'       : [32, 16, 8],  # filter sizes for TWO convolutional layers\n",
    "                'keep_propn'    : 0.9,          # proportion kept in dropout, if applied\n",
    "                'kinit'         : 'he_uniform', # alternatives: glorot_uniform, he_uniform etc\n",
    "                'dense_dims'    : [256, 64, 16, latent_dims],    # node sizes for dense layers\n",
    "                'fnl_activation': 'linear'\n",
    "                }\n",
    "\n",
    "# Instantiate the new model class\n",
    "encoder_test = encoder_line(name='encoder_test', params_dict=params_dict_enc)\n",
    "encoder_test.layers\n",
    "# Execute the model on the example data (may submit numpy array or tensor)\n",
    "encoder_test_output = encoder_test( train_cln[0:5,:,:,:] )\n",
    "\n",
    "# Is the output shape right? \n",
    "print(\"Expecting encoder output shape: (samples, latent_space_dims)\")\n",
    "print(\"Actual encoder output shape   :  \", encoder_test_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"encoder_test\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 64, 64, 32)        320       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 64, 64, 32)        128       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 1)         33        \n_________________________________________________________________\np_re_lu (PReLU)              (None, 64, 64, 32)        131072    \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 32, 32, 16)        4624      \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 32, 32, 16)        64        \n_________________________________________________________________\nadd (Add)                    (None, 32, 32, 16)        0         \n_________________________________________________________________\np_re_lu_1 (PReLU)            (None, 32, 32, 16)        16384     \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 16, 16, 1)         17        \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 16, 16, 8)         1160      \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 16, 16, 8)         32        \n_________________________________________________________________\nadd_1 (Add)                  (None, 16, 16, 8)         0         \n_________________________________________________________________\np_re_lu_2 (PReLU)            (None, 16, 16, 8)         2048      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 8, 8, 8)           0         \n_________________________________________________________________\nflatten (Flatten)            (None, 512)               0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               131328    \n_________________________________________________________________\np_re_lu_3 (PReLU)            (None, 256)               256       \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                16448     \n_________________________________________________________________\np_re_lu_4 (PReLU)            (None, 64)                64        \n_________________________________________________________________\ndense_2 (Dense)              (None, 16)                1040      \n_________________________________________________________________\np_re_lu_5 (PReLU)            (None, 16)                16        \n_________________________________________________________________\ndense_3 (Dense)              (None, 7)                 119       \n=================================================================\nTotal params: 305,153\nTrainable params: 305,041\nNon-trainable params: 112\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# VIEW SUMMARY OF ENCODER\n",
    "encoder_test.build_graph(input_shape=(None, 64, 64, 1))\n",
    "encoder_test.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECODER\n",
    "\n",
    "The decoder is constructed using fairly standard architecture. The latent space is read into a block of three dense layers, which then feed into convolutional blocks. Each block consists of UpSampling, Conv2D, BatchNorm. The output is the line image that the img.line method would have given for those latent space variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DECODER MODEL BUILDING\n",
    "\n",
    "class decoder_line(tf.keras.Model):\n",
    "    def __init__(self, params_dict, name, **kwargs):\n",
    "        super(decoder_line, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        # Get params\n",
    "        self.filters       = params_dict.get('filters')    # is list, not single item\n",
    "        self.dense_dims    = params_dict.get('dense_dims') # is list, not single item\n",
    "        self.kernel_size   = params_dict.get('kernel_size')\n",
    "        self.kinit         = params_dict.get('kinit')\n",
    "        self.leaky_alpha   = params_dict.get('leaky_alpha')\n",
    "        self.fnl_activation= params_dict.get('fnl_activation')\n",
    "        self.relu_max_val  = params_dict.get('relu_max_val')\n",
    "        self.reshaped_dim  = int( tf.math.pow(float(self.dense_dims[-1]),1.0/3.0) ) # cube root\n",
    "        #self.keep_propn   = params_dict.get('keep_propn')\n",
    "\n",
    "        if self.fnl_activation == 'relu':\n",
    "            self.fnl_activation_txt = None\n",
    "            self.relumax  = ReLU(max_value=self.relu_max_val, negative_slope=0.0, threshold=0.0)\n",
    "        else:\n",
    "            self.fnl_activation_txt = fnl_activation\n",
    "\n",
    "        # Specify layers\n",
    "        # Dense inputs   = (samples, latent_space_dims)\n",
    "\n",
    "        self.dense1   = Dense(self.dense_dims[0], kernel_initializer=self.kinit, activation=None)\n",
    "        self.dense1lky= PReLU(alpha_initializer='zeros') # LeakyReLU(alpha=self.leaky_alpha)\n",
    "\n",
    "        self.dense2   = Dense(self.dense_dims[1], kernel_initializer=self.kinit, activation=None)\n",
    "        self.dense2lky= PReLU(alpha_initializer='zeros') # LeakyReLU(alpha=self.leaky_alpha)\n",
    "\n",
    "        self.dense3   = Dense(self.dense_dims[-1], kernel_initializer=self.kinit, activation=None)\n",
    "        self.dense3lky= PReLU(alpha_initializer='zeros') # LeakyReLU(alpha=self.leaky_alpha)\n",
    "\n",
    "        # Reshape (samples, rows, cols, channels)\n",
    "        # samples (first dim) is implied\n",
    "        # rows = cols = pow(dense_dims[2])-1/3 , ie cube root\n",
    "        # channels = 1\n",
    "        self.reshape1 = Reshape( (self.reshaped_dim, self.reshaped_dim, self.reshaped_dim) )\n",
    "\n",
    "        self.upsample1= UpSampling2D((2,2))\n",
    "        self.conv1    = Conv2D(filters=self.filters[0], kernel_size=3, kernel_initializer=self.kinit, padding='same', activation=None)\n",
    "        self.batnm1   = BatchNormalization(axis=3)\n",
    "        self.conv1lky = PReLU(alpha_initializer='zeros') # LeakyReLU(alpha=self.leaky_alpha)\n",
    "\n",
    "        self.upsample2= UpSampling2D((2,2))\n",
    "        self.conv2    = Conv2D(filters=self.filters[1], kernel_size=3, kernel_initializer=self.kinit, padding='same', activation=None)\n",
    "        self.batnm2   = BatchNormalization(axis=3)\n",
    "        self.conv2lky = PReLU(alpha_initializer='zeros') # LeakyReLU(alpha=self.leaky_alpha)\n",
    "\n",
    "        self.upsample3= UpSampling2D((2,2))\n",
    "        self.conv3    = Conv2D(filters=self.filters[2], kernel_size=3, kernel_initializer=self.kinit, padding='same', activation=self.fnl_activation_txt)\n",
    "\n",
    "    # we need this in order to call model.summary()\n",
    "    # does not need to be a tf function\n",
    "    # @tf.function\n",
    "    def build_graph(self, input_shape): \n",
    "        input_shape_nobatch = input_shape[1:]\n",
    "        self.build(input_shape)\n",
    "        inputs = tf.keras.Input(shape=input_shape_nobatch)\n",
    " \n",
    "        if not hasattr(self, 'call'):\n",
    "            raise AttributeError(\"Must define 'call' method for class\")\n",
    "        \n",
    "        _ = self.call(inputs)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # Define forward pass here,\n",
    "        # 'training' is applicable to BatchNorm and DropOut\n",
    "        # eg self.dropout(x, training=training)\n",
    "        # keras.fit would normally do this, but we're using gradient tape\n",
    "        # Uses layers previously defined (in `__init__`).\n",
    "        \n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense1lky(x)\n",
    "\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense2lky(x)\n",
    "        \n",
    "        x = self.dense3(x)\n",
    "        x = self.dense3lky(x)\n",
    "\n",
    "        x = self.reshape1(x)\n",
    "\n",
    "        x = self.upsample1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.batnm1(x)\n",
    "        x = self.conv1lky(x)\n",
    "        \n",
    "        x = self.upsample2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batnm2(x)\n",
    "        x = self.conv2lky(x)\n",
    "\n",
    "        x = self.upsample3(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        if self.fnl_activation == 'relu':\n",
    "            x = self.relumax(x)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Expecting decoder output shape: (samples, w, h, channels)\nActual decoder output shape   :   (5, 64, 64, 1)\n"
    }
   ],
   "source": [
    "\n",
    "### TEST DECODER\n",
    "\n",
    "# variety of choices for final activation; relumax, sigmoid, tanh\n",
    "# These affect architecture of model\n",
    "relu_max_val = np.max(train_cln)\n",
    "\n",
    "# set params\n",
    "params_dict_dec = {\n",
    "                'kernel_size'   : 3,\n",
    "                'filters'       : [32, 16, 1],     # filter sizes for THREE convolutional layers. Penultimate is always half of 64. Final is always 1 for BW image\n",
    "                'kinit'         : 'glorot_normal', # alternatives: glorot_uniform, he_uniform etc\n",
    "                'leaky_alpha'   : 0.2,             # if zero, then applies ReLu activation\n",
    "                'dense_dims'    : [latent_dims, 256, 512],    # node qty for each dense layer. Final must be a square of an integer\n",
    "                'fnl_activation': 'relu',\n",
    "                'relu_max_val'  : relu_max_val*2\n",
    "                }\n",
    "\n",
    "# Instantiate the new model class\n",
    "decoder_test = decoder_line(name='decoder_test', params_dict=params_dict_dec)\n",
    "\n",
    "# Execute the model on the example data\n",
    "decoder_test_output = decoder_test( encoder_test_output )\n",
    "\n",
    "# Is the output shape right?\n",
    "print(\"Expecting decoder output shape: (samples, w, h, channels)\")\n",
    "print(\"Actual decoder output shape   :  \", decoder_test_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"decoder_test\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nre_lu (ReLU)                 (None, 64, 64, 1)         0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 7)                 56        \n_________________________________________________________________\np_re_lu_6 (PReLU)            (None, 7)                 7         \n_________________________________________________________________\ndense_5 (Dense)              (None, 256)               2048      \n_________________________________________________________________\np_re_lu_7 (PReLU)            (None, 256)               256       \n_________________________________________________________________\ndense_6 (Dense)              (None, 512)               131584    \n_________________________________________________________________\np_re_lu_8 (PReLU)            (None, 512)               512       \n_________________________________________________________________\nreshape (Reshape)            (None, 8, 8, 8)           0         \n_________________________________________________________________\nup_sampling2d (UpSampling2D) (None, 16, 16, 8)         0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 16, 16, 32)        2336      \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 16, 16, 32)        128       \n_________________________________________________________________\np_re_lu_9 (PReLU)            (None, 16, 16, 32)        8192      \n_________________________________________________________________\nup_sampling2d_1 (UpSampling2 (None, 32, 32, 32)        0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 32, 32, 16)        4624      \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 32, 32, 16)        64        \n_________________________________________________________________\np_re_lu_10 (PReLU)           (None, 32, 32, 16)        16384     \n_________________________________________________________________\nup_sampling2d_2 (UpSampling2 (None, 64, 64, 16)        0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 64, 64, 1)         145       \n=================================================================\nTotal params: 166,336\nTrainable params: 166,240\nNon-trainable params: 96\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "\n",
    "# VIEW SUMMARY OF DECODER\n",
    "decoder_test.build_graph(input_shape=(None, latent_dims))\n",
    "decoder_test.summary()\n"
   ]
  },
  {
   "source": [
    "## Comparing Output with Image.Draw\n",
    "\n",
    "When inspecting the output images from the decoder we'll want to compare them to what the Image.Draw method would have done with the same latent variables. Here's the funciton for that:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert line specification into a line image\n",
    "# Required for visually displaying results of training\n",
    "\n",
    "w, h = (64, 64)\n",
    "\n",
    "def reconstruct_lines(latents_batch_tensor, unscale_data=False, w=w, h=h, mn=None, sd=None, pk2pk=255, mins=0):\n",
    "    print(\"reconstruct_lines started\")\n",
    "    # convert to numpy\n",
    "    latents_np = np.array(latents_batch_tensor)\n",
    "    \n",
    "    if unscale_data:\n",
    "        if method == 'standardise':\n",
    "            # de-standardise (start, end, width, colour, etc)\n",
    "            latents_np = de_standardise(array_np=array_np, mn=mn, sd=sd)\n",
    "        elif method == 'range_shift':\n",
    "            # return range to normal\n",
    "            latents_np = de_range_shift(array_np=latents_np, mins=mins, pk2pk=pk2pk)\n",
    "        else:\n",
    "            print(\"ERROR: Data processing method unkown\")\n",
    "            return AssertionError\n",
    "\n",
    "    # get batch size\n",
    "    batch_size = latents_np.shape[0]\n",
    "\n",
    "    # initialise list for ouput, will convert to numpy later.\n",
    "    reconst_np = []\n",
    "    # reconst_ls = [] # list for images, not numpies.\n",
    "\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        # ensure data is clipped to range 0-255 and is integer\n",
    "        latents_ls = (np.clip(latents_np[1,:], a_min=0, a_max=255)).tolist()\n",
    "        latents_ls = [int(a) for a in latents_ls]\n",
    "\n",
    "        # separate out the features\n",
    "        x_start, y_start, x_end, y_end, linecol, linewid, imgcolr = latents_ls\n",
    "\n",
    "        # instantiate image. NB mode 'L' is 8bit Greyscale\n",
    "        img  = Image.new(mode='L', size=(w, h), color=imgcolr)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        # add line(s)\n",
    "        shape = [(x_start, y_start), (x_end, y_end)]\n",
    "        draw.line(shape, fill=linecol, width=linewid)\n",
    "\n",
    "        # expand dims so we have a channel dim\n",
    "        img_np = np.expand_dims(np.array(img), axis=-1)\n",
    "\n",
    "        # add to list of images\n",
    "        reconst_np.append(img_np)\n",
    "        # reconst_ls.append(img)\n",
    "    \n",
    "    # convert list of numpys into a numpy stack\n",
    "    reconst_np = np.stack(reconst_np, axis=0)  \n",
    "\n",
    "    return reconst_np # ,reconst_ls"
   ]
  },
  {
   "source": [
    "## Helper Functions for Decoder Training\n",
    "\n",
    "We'll need the following helper functions to train the decoder:\n",
    "- Loss function\n",
    "- Batch fetcher\n",
    "- Save Model\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the loss_object we could use a number of loss functions, most commonly:\n",
    "# tf.keras.losses.mean_squared_error\n",
    "# OR, SSIM, which is optimised for images:\n",
    "\n",
    "def SSIM_loss(y_true, y_pred):\n",
    "    # Note, ssim returns +1 when perfect match, -1 when perfectly opposite\n",
    "    # So, we multiply by -1 to return a 'loss' which can be minimised.\n",
    "    return tf.image.ssim(img1=y_true, img2=y_pred, max_val=2.25, \n",
    "                         filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)*-1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Batch Fetcher\n",
    "\n",
    "# akin to keras's shuffle when using keras.fit\n",
    "# which we can't use cos we're using gradient tape.\n",
    "def get_batch_mask(dataset_np, batch_size):\n",
    "    \n",
    "    # samples in dataset\n",
    "    sample_max = dataset_np.shape[0]\n",
    "    # randomly select next batch\n",
    "    sample_ids = np.random.randint(low = 0, high = sample_max, size = batch_size) \n",
    "\n",
    "    return sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Expect loss shape = (5,)\nActual loss shape = (5,)\n"
    }
   ],
   "source": [
    "# Test SSIM loss function on Decoder\n",
    "\n",
    "test_mask   = get_batch_mask(testi_ltn, batch_size=5)\n",
    "test_x      = testi_ltn[test_mask,...]\n",
    "test_y_true = tf.convert_to_tensor(testi_cln[test_mask,...], dtype=tf.float32)\n",
    "test_y_pred = decoder_test(test_x)\n",
    "loss_batch  = SSIM_loss(y_true=test_y_true, y_pred=test_y_pred)\n",
    "\n",
    "print(\"Expect loss shape = (5,)\")\n",
    "print(\"Actual loss shape =\", loss_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Model Function\n",
    "\n",
    "subfolders = ['Line_SaveModels']\n",
    "filename   = 'model_line_DecodeByClass'\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "def save_model_custom(model_object, proj_root=proj_root, subfolders=subfolders, filename=filename):\n",
    "    \n",
    "    # save keras model (ie serialize and send to file)\n",
    "    # Saving the model to HDF5 format does not work for subclassed models, \n",
    "    # because such models are defined via the body of a Python method, which isn't safely serializable. \n",
    "    # COMMENTED OUT\n",
    "    # model_object.save(os.path.join(proj_root,model_root,filename+'_model.h5'), save_format='tf')\n",
    "\n",
    "    # save weights\n",
    "    model_object.save_weights(os.path.join(proj_root, *subfolders, filename+'_weights.tf'))\n",
    "\n",
    "    # save summary text\n",
    "    filename_txt = os.path.join(proj_root, *subfolders, filename+'_summary.txt')\n",
    "    with open(filename_txt, 'w') as f:\n",
    "        with redirect_stdout(f):\n",
    "            model_object.summary()\n",
    "    \n",
    "    # save graph image\n",
    "    # COMMENTED OUT\n",
    "    # plot_model does not work properly for subclassed models either. Hence commented out\n",
    "    # filename_png = os.path.join(proj_root,model_root,filename+'_graph.png')\n",
    "    # plot_model(model_object, to_file=os.path.join(proj_root,model_root,filename_png), show_shapes=True)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING FUNCTION\n",
    "\n",
    "We will create our own training function, as opposed to use keras.fit(). This gives a little more control should we need it.\n",
    "\n",
    "One function will be created which can train the decoder, the encoder or an entire autoencoder. The function will allow for each component to be trained separately, together or with one component having fixed weights whilst the other is trainable.\n",
    "\n",
    "Beware this is a gradient tape training loop set to 'persistent' \n",
    "   See intro to such loops at\n",
    "\n",
    "   - https://www.tensorflow.org/tutorials/customization/autodiff\n",
    "\n",
    "   - https://tensorflow.rstudio.com/tutorials/advanced/customization/autodiff/\n",
    "\n",
    "   and potential hiccups at:\n",
    "\n",
    "   - http://blog.ai.ovgu.de/posts/jens/2019/001_tf20_pitfalls/index.html\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first a function to calculate gradients for a model\n",
    "      \n",
    "def update_weights(train_model, tape, loss, optimizer):\n",
    "    train_model_gradients = tape.gradient(loss, train_model.trainable_variables)\n",
    "    grads_and_vars = list(zip(train_model_gradients, train_model.trainable_variables))\n",
    "    optimizer.apply_gradients(grads_and_vars = grads_and_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(  train_encoder,         # can be 'None' if training decoder only\n",
    "                  train_decoder,         # can be 'None' if training encoder only\n",
    "                  is_encoder_trainable,  # boolean, fixes weights as appropriate for training\n",
    "                  is_decoder_trainable,  # boolean, fixes weights as appropriate for training\n",
    "                  model_type,            # encoder only, decoder only, autoencoder (ie encoder+decoder)\n",
    "                  train_x, \n",
    "                  train_y,\n",
    "                  valid_x,\n",
    "                  valid_y,        \n",
    "                  batch_size, \n",
    "                  num_epochs, \n",
    "                  optimizer,\n",
    "                  loss_object,\n",
    "                  earlystop):\n",
    "\n",
    "    assert model_type in ['encoder', 'decoder', 'autoencoder'], \"Unknown Model Type. Must be in ['encoder', 'decoder', 'autoencoder']\"\n",
    "\n",
    "    # If autoencoding, then train_y = train_x\n",
    "    if model_type == 'autoencoder':\n",
    "        assert train_x.shape[0] > 0, \"No training data\"\n",
    "        train_y = train_x\n",
    "        valid_y = valid_x\n",
    "    else:\n",
    "        # else ensure we have both y and x, and that they are of equal length\n",
    "        assert train_y.shape[0] == train_x.shape[0]\n",
    "        assert valid_y.shape[0] == valid_x.shape[0]\n",
    "\n",
    "    # set model trainability\n",
    "    if type(train_encoder)==bool:\n",
    "        train_encoder = set_model_trainability(model=train_encoder, is_trainable=is_encoder_trainable)\n",
    "\n",
    "    if type(train_decoder)==bool:\n",
    "        train_decoder = set_model_trainability(model=train_decoder, is_trainable=is_decoder_trainable)\n",
    "\n",
    "    # calculate batches per epoch\n",
    "    batches_per_epoch = math.ceil(len(train_x)/batch_size)\n",
    "\n",
    "    # initialise loss params for each epoch\n",
    "    batch_losses = []\n",
    "    epoch_losses = []\n",
    "\n",
    "    # loop over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # loop over batches in a single epoch\n",
    "        for batch_id in range(batches_per_epoch):\n",
    "        \n",
    "            # randomly sample next batch\n",
    "            mask    = get_batch_mask(train_x, batch_size)\n",
    "            x_batch = tf.convert_to_tensor(train_x[mask,...], dtype=tf.float32)\n",
    "            y_true  = tf.convert_to_tensor(train_y[mask,...], dtype=tf.float32)\n",
    "\n",
    "            # The forward pass is recorded by a GradientTape, \n",
    "            # and during the backward pass we explicitly calculate gradients \n",
    "            # of the loss with respect to the models weights. \n",
    "            # These weights are then adjusted by the optimizer.\n",
    "            with tf.GradientTape(persistent=True) as tape: #, watch_accessed_variables=False\n",
    "                # Automatically watch all trainable variables\n",
    "                # tape.watch(x_batch)\n",
    "\n",
    "            #### RECORD FORWARD PASS ###\n",
    "                if model_type == 'autoencoder':\n",
    "                    latent = train_encoder(x_batch)\n",
    "                    y_pred = train_decoder(latent)\n",
    "\n",
    "                elif model_type == 'encoder':\n",
    "                    y_pred = train_encoder(x_batch)\n",
    "\n",
    "                elif model_type == 'decoder':\n",
    "                    y_pred = train_decoder(x_batch)\n",
    "                else:\n",
    "                    print('No such model type')\n",
    "                    break\n",
    "\n",
    "            ### CALCULATE LOSS ###\n",
    "                loss = loss_object(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "            # End of Gradient Tape, Forward prop has ended for the batch\n",
    "\n",
    "            # record batch losses\n",
    "            batch_losses.append([epoch, batch_id, float(tf.reduce_mean(loss))])\n",
    "\n",
    "            # update encoder weights etc\n",
    "            if train_encoder is not None and is_encoder_trainable:\n",
    "                update_weights(train_model=train_encoder, tape=tape, loss=loss, optimizer=optimizer) \n",
    "\n",
    "            # update decoder weights etc\n",
    "            if train_decoder is not None and is_decoder_trainable:\n",
    "                update_weights(train_model=train_decoder, tape=tape, loss=loss, optimizer=optimizer)             \n",
    "\n",
    "        # end of batch loop\n",
    "\n",
    "        # record epoch losses for TRAINING data\n",
    "        epoch_loss = sum([col[2] for col in batch_losses[-batches_per_epoch:]])/batches_per_epoch\n",
    "        \n",
    "        # record epoch losses for VALIDATION data\n",
    "        if model_type == 'autoencoder':\n",
    "            valid_latent = train_encoder(valid_x)\n",
    "            valid_y_pred = train_decoder(valid_latent)\n",
    "        elif model_type == 'encoder':\n",
    "            valid_y_pred = train_encoder(valid_x)\n",
    "        else : # must be decoder\n",
    "            valid_y_pred = train_decoder(valid_x)\n",
    "        \n",
    "        epoch_loss_valid = float(tf.reduce_mean(loss_object(y_true=valid_y, y_pred=valid_y_pred)))\n",
    "\n",
    "        # save both epoch losses to list\n",
    "        epoch_losses.append([epoch, epoch_loss, epoch_loss_valid])\n",
    "\n",
    "        # every few epochs print results to screen\n",
    "        if epoch % 5 == 0 or epoch == num_epochs-1: #every fifth epoch\n",
    "\n",
    "            # print losses to screen\n",
    "            print( 'Epoch {}:'.format(epoch), ' loss_train: ', epoch_loss, ' loss_valid: ', epoch_loss_valid )\n",
    "\n",
    "        # Early Stopping. cease training if too many epochs without progress\n",
    "        # We can consider this if already done a certain number of epochs\n",
    "        if epoch > earlystop:\n",
    "            # what was the lowest loss prior to the last bunch of epochs?\n",
    "            lowest_epoch_loss_prior  = min([col[1] for col in epoch_losses[:epoch-earlystop]])\n",
    "            # what was the lowest loss in the last bunch of epochs\n",
    "            lowest_epoch_loss_recent = min([col[1] for col in epoch_losses[-earlystop:]])\n",
    "            # if the recent bunch can't beat what happened before, then break the loop\n",
    "            if lowest_epoch_loss_recent > lowest_epoch_loss_prior:\n",
    "                print(\"No progress. Applied early stopping at epoch = \", epoch)\n",
    "                break\n",
    "\n",
    "    # end of epoch loop\n",
    "    del tape\n",
    "\n",
    "    # convert training results to pandas for convenience\n",
    "    epoch_losses_pd = pd.DataFrame(data=epoch_losses, columns=['epoch', 'loss_train', 'loss_valid'])\n",
    "\n",
    "    return train_encoder, train_decoder, epoch_losses_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET UP MODEL, OPTIMISER, LOSS, ETC\n",
    "### SET UP THE TRAINING LOOP\n",
    "\n",
    "### Epochs & Batches\n",
    "num_epochs = 10\n",
    "batch_size = 100 # save as VAE for similar sample size reasons\n",
    "earlystop  = 30  # epochs without progress which trigger early stopping of training\n",
    "\n",
    "# The optimizer\n",
    "optimizer  = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# instantiate model to be trained\n",
    "decoder = decoder_line(name='decoder_line', params_dict=params_dict_dec)\n",
    "\n",
    "# decoder loss function\n",
    "loss_object = tf.keras.losses.mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<tensorflow.python.keras.layers.advanced_activations.ReLU at 0x1804aebd408>,\n <tensorflow.python.keras.layers.core.Dense at 0x180da547788>,\n <tensorflow.python.keras.layers.advanced_activations.PReLU at 0x180da547d08>,\n <tensorflow.python.keras.layers.core.Dense at 0x180da547f88>,\n <tensorflow.python.keras.layers.advanced_activations.PReLU at 0x180da54aec8>,\n <tensorflow.python.keras.layers.core.Dense at 0x180da54fa48>,\n <tensorflow.python.keras.layers.advanced_activations.PReLU at 0x180da553548>,\n <tensorflow.python.keras.layers.core.Reshape at 0x180da553e48>,\n <tensorflow.python.keras.layers.convolutional.UpSampling2D at 0x180da557948>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x180da55d508>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x180da55dec8>,\n <tensorflow.python.keras.layers.advanced_activations.PReLU at 0x1808dffd288>,\n <tensorflow.python.keras.layers.convolutional.UpSampling2D at 0x1804aef1a48>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x180da4f6d88>,\n <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x180da4ccf88>,\n <tensorflow.python.keras.layers.advanced_activations.PReLU at 0x180da4e8b88>,\n <tensorflow.python.keras.layers.convolutional.UpSampling2D at 0x18071008d88>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x180da4da048>]"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# inspect decoder model layers\n",
    "\n",
    "decoder.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0:  loss_train:  0.04701102026774404  loss_valid:  0.010636638849973679\nEpoch 5:  loss_train:  0.006563561837231279  loss_valid:  0.006796401459723711\nEpoch 9:  loss_train:  0.006348709851042363  loss_valid:  0.006507398560643196\n"
    }
   ],
   "source": [
    "# train decoder\n",
    "_, decoder, epoch_losses_dec = train_model( train_encoder = None,\n",
    "                                            train_decoder = decoder,\n",
    "                                            model_type    = 'decoder',      # CHOICE: encoder, decoder, autoencoder (ie encoder+decoder)\n",
    "                                            train_x       = train_ltn, \n",
    "                                            train_y       = train_cln,      # if training autoencoder then beware that y=x\n",
    "                                            valid_x       = valid_ltn,\n",
    "                                            valid_y       = valid_cln,      # if training autoencoder then beware that y=x\n",
    "                                            batch_size    = batch_size, \n",
    "                                            num_epochs    = num_epochs, \n",
    "                                            optimizer     = optimizer,\n",
    "                                            loss_object   = loss_object,\n",
    "                                            earlystop     = earlystop,\n",
    "                                            is_encoder_trainable = None,    # boolean, fixes weights as appropriate for training\n",
    "                                            is_decoder_trainable = True)    # boolean, fixes weights as appropriate for training\n"
   ]
  },
  {
   "source": [
    "## Decoder Training Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"327.930058pt\" version=\"1.1\" viewBox=\"0 0 411.109687 327.930058\" width=\"411.109687pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 327.930058 \r\nL 411.109687 327.930058 \r\nL 411.109687 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 46.789688 292.217371 \r\nL 403.909688 292.217371 \r\nL 403.909688 26.105371 \r\nL 46.789688 26.105371 \r\nz\r\n\" style=\"fill:#ebebeb;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 63.022415 292.217371 \r\nL 63.022415 26.105371 \r\n\" style=\"fill:none;stroke:#ffffff;\"/>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <path d=\"M 63.022415 292.217371 \r\n\" style=\"fill:none;stroke:#333333;stroke-width:1.5;\"/>\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 2.75 \r\n\" id=\"ma73acd8c71\" style=\"stroke:#333333;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"fill:#333333;stroke:#333333;\" x=\"63.022415\" xlink:href=\"#ma73acd8c71\" y=\"292.217371\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g style=\"fill:#4d4d4d;\" transform=\"translate(60.222915 303.853996)scale(0.088 -0.088)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 153.204233 292.217371 \r\nL 153.204233 26.105371 \r\n\" style=\"fill:none;stroke:#ffffff;\"/>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <path d=\"M 153.204233 292.217371 \r\n\" style=\"fill:none;stroke:#333333;stroke-width:1.5;\"/>\r\n      <g>\r\n       <use style=\"fill:#333333;stroke:#333333;\" x=\"153.204233\" xlink:href=\"#ma73acd8c71\" y=\"292.217371\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 2.5 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g style=\"fill:#4d4d4d;\" transform=\"translate(146.206858 303.853996)scale(0.088 -0.088)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 243.386051 292.217371 \r\nL 243.386051 26.105371 \r\n\" style=\"fill:none;stroke:#ffffff;\"/>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <path d=\"M 243.386051 292.217371 \r\n\" style=\"fill:none;stroke:#333333;stroke-width:1.5;\"/>\r\n      <g>\r\n       <use style=\"fill:#333333;stroke:#333333;\" x=\"243.386051\" xlink:href=\"#ma73acd8c71\" y=\"292.217371\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 5 -->\r\n      <g style=\"fill:#4d4d4d;\" transform=\"translate(240.586551 303.853996)scale(0.088 -0.088)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 333.567869 292.217371 \r\nL 333.567869 26.105371 \r\n\" style=\"fill:none;stroke:#ffffff;\"/>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <path d=\"M 333.567869 292.217371 \r\n\" style=\"fill:none;stroke:#333333;stroke-width:1.5;\"/>\r\n      <g>\r\n       <use style=\"fill:#333333;stroke:#333333;\" x=\"333.567869\" xlink:href=\"#ma73acd8c71\" y=\"292.217371\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 7.5 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g style=\"fill:#4d4d4d;\" transform=\"translate(326.570494 303.853996)scale(0.088 -0.088)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 108.113324 292.217371 \r\nL 108.113324 26.105371 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-width:0.5;\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_10\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 198.295142 292.217371 \r\nL 198.295142 26.105371 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-width:0.5;\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 288.47696 292.217371 \r\nL 288.47696 26.105371 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-width:0.5;\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_12\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 378.658778 292.217371 \r\nL 378.658778 26.105371 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-width:0.5;\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_5\">\r\n     <!-- Epoch -->\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n      <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n      <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n     </defs>\r\n     <g transform=\"translate(202.747656 318.442402)scale(0.11 -0.11)\">\r\n      <use xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 46.789688 258.398057 \r\nL 403.909688 258.398057 \r\n\" style=\"fill:none;stroke:#ffffff;\"/>\r\n     </g>\r\n     <g id=\"line2d_14\">\r\n      <path d=\"M 46.789688 258.398057 \r\n\" style=\"fill:none;stroke:#333333;stroke-width:1.5;\"/>\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -2.75 0 \r\n\" id=\"mdfa741f267\" style=\"stroke:#333333;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"fill:#333333;stroke:#333333;\" x=\"46.789688\" xlink:href=\"#mdfa741f267\" y=\"258.398057\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 0.01 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g style=\"fill:#4d4d4d;\" transform=\"translate(22.245938 260.826307)scale(0.088 -0.088)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_15\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 46.789688 198.90316 \r\nL 403.909688 198.90316 \r\n\" style=\"fill:none;stroke:#ffffff;\"/>\r\n     </g>\r\n     <g id=\"line2d_16\">\r\n      <path d=\"M 46.789688 198.90316 \r\n\" style=\"fill:none;stroke:#333333;stroke-width:1.5;\"/>\r\n      <g>\r\n       <use style=\"fill:#333333;stroke:#333333;\" x=\"46.789688\" xlink:href=\"#mdfa741f267\" y=\"198.90316\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.02 -->\r\n      <g style=\"fill:#4d4d4d;\" transform=\"translate(22.245938 201.33141)scale(0.088 -0.088)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_17\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 46.789688 139.408262 \r\nL 403.909688 139.408262 \r\n\" style=\"fill:none;stroke:#ffffff;\"/>\r\n     </g>\r\n     <g id=\"line2d_18\">\r\n      <path d=\"M 46.789688 139.408262 \r\n\" style=\"fill:none;stroke:#333333;stroke-width:1.5;\"/>\r\n      <g>\r\n       <use style=\"fill:#333333;stroke:#333333;\" x=\"46.789688\" xlink:href=\"#mdfa741f267\" y=\"139.408262\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.03 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g style=\"fill:#4d4d4d;\" transform=\"translate(22.245938 141.836512)scale(0.088 -0.088)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_19\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 46.789688 79.913364 \r\nL 403.909688 79.913364 \r\n\" style=\"fill:none;stroke:#ffffff;\"/>\r\n     </g>\r\n     <g id=\"line2d_20\">\r\n      <path d=\"M 46.789688 79.913364 \r\n\" style=\"fill:none;stroke:#333333;stroke-width:1.5;\"/>\r\n      <g>\r\n       <use style=\"fill:#333333;stroke:#333333;\" x=\"46.789688\" xlink:href=\"#mdfa741f267\" y=\"79.913364\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.04 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g style=\"fill:#4d4d4d;\" transform=\"translate(22.245938 82.341614)scale(0.088 -0.088)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_21\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 46.789688 288.145506 \r\nL 403.909688 288.145506 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-width:0.5;\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_22\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 46.789688 228.650608 \r\nL 403.909688 228.650608 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-width:0.5;\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_23\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 46.789688 169.155711 \r\nL 403.909688 169.155711 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-width:0.5;\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_24\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 46.789688 109.660813 \r\nL 403.909688 109.660813 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-width:0.5;\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_25\">\r\n      <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 46.789688 50.165915 \r\nL 403.909688 50.165915 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-width:0.5;\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_10\">\r\n     <!-- Loss -->\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n      <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n     </defs>\r\n     <g transform=\"translate(15.558281 169.497277)rotate(-90)scale(0.11 -0.11)\">\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_26\">\r\n    <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 63.022415 38.201371 \r\nL 99.095142 269.885684 \r\nL 135.167869 276.663289 \r\nL 171.240597 277.514044 \r\nL 207.313324 278.305393 \r\nL 243.386051 278.843111 \r\nL 279.458778 278.924066 \r\nL 315.531506 279.752244 \r\nL 351.604233 280.11712 \r\nL 387.67696 280.121371 \r\n\" style=\"fill:none;stroke:#000000;stroke-width:0.886227;\"/>\r\n   </g>\r\n   <g id=\"line2d_27\">\r\n    <path clip-path=\"url(#p5c2f4425a8)\" d=\"M 63.022415 254.610381 \r\nL 99.095142 272.657882 \r\nL 135.167869 275.126046 \r\nL 171.240597 276.013622 \r\nL 207.313324 276.859379 \r\nL 243.386051 277.457834 \r\nL 279.458778 277.87605 \r\nL 315.531506 278.233706 \r\nL 351.604233 278.638405 \r\nL 387.67696 279.177254 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-width:0.886227;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"text_11\">\r\n   <!-- Training Losses -->\r\n   <defs>\r\n    <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n    <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n    <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n    <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n    <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n    <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-103\"/>\r\n    <path id=\"DejaVuSans-32\"/>\r\n    <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n   </defs>\r\n   <g transform=\"translate(169.478156 17.229938)scale(0.132 -0.132)\">\r\n    <use xlink:href=\"#DejaVuSans-84\"/>\r\n    <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\r\n    <use x=\"87.447266\" xlink:href=\"#DejaVuSans-97\"/>\r\n    <use x=\"148.726562\" xlink:href=\"#DejaVuSans-105\"/>\r\n    <use x=\"176.509766\" xlink:href=\"#DejaVuSans-110\"/>\r\n    <use x=\"239.888672\" xlink:href=\"#DejaVuSans-105\"/>\r\n    <use x=\"267.671875\" xlink:href=\"#DejaVuSans-110\"/>\r\n    <use x=\"331.050781\" xlink:href=\"#DejaVuSans-103\"/>\r\n    <use x=\"394.527344\" xlink:href=\"#DejaVuSans-32\"/>\r\n    <use x=\"426.314453\" xlink:href=\"#DejaVuSans-76\"/>\r\n    <use x=\"480.277344\" xlink:href=\"#DejaVuSans-111\"/>\r\n    <use x=\"541.458984\" xlink:href=\"#DejaVuSans-115\"/>\r\n    <use x=\"593.558594\" xlink:href=\"#DejaVuSans-115\"/>\r\n    <use x=\"645.658203\" xlink:href=\"#DejaVuSans-101\"/>\r\n    <use x=\"707.181641\" xlink:href=\"#DejaVuSans-115\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p5c2f4425a8\">\r\n   <rect height=\"266.112\" width=\"357.12\" x=\"46.789688\" y=\"26.105371\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<ggplot: (-9223371933608425300)>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "### CHART TRAINING HISTORY\n",
    "\n",
    "# save training history to file\n",
    "epoch_losses_dec.to_csv(os.path.join(proj_root, *subfolders, 'decoder_from_latents_epoch_history.csv'))\n",
    "\n",
    "#plot training history\n",
    "(p9.ggplot(data   = epoch_losses_dec,\n",
    "           mapping= p9.aes(x='epoch'))\n",
    "    + p9.geom_line(p9.aes(y='loss_train'), color='black')\n",
    "    + p9.geom_line(p9.aes(y='loss_valid'), color='red')\n",
    "    + p9.xlab('Epoch')\n",
    "    + p9.ylab('Loss')\n",
    "    + p9.ggtitle('Training Losses')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE DECODER\n",
    "\n",
    "# Save encoder\n",
    "filename = 'decoder_from_latents'\n",
    "save_model_custom(model_object = decoder,\n",
    "                  filename     = filename)\n",
    "\n"
   ]
  },
  {
   "source": [
    "Let's compare the decoder's intrpretation of the latent space with what the Image.Draw method would have drawn with the same variables.\n",
    "The below chart shows the trained decoder gives excelent results."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 12 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"252.074665pt\" version=\"1.1\" viewBox=\"0 0 247.806039 252.074665\" width=\"247.806039pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 252.074665 \r\nL 247.806039 252.074665 \r\nL 247.806039 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 41.819397 \r\nL 57.987857 41.819397 \r\nL 57.987857 10.75654 \r\nL 26.925 10.75654 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pf5852f33ca)\">\r\n    <image height=\"32\" id=\"imaged5168c3d82\" transform=\"scale(1 -1)translate(0 -32)\" width=\"32\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABHNCSVQICAgIfAhkiAAAARRJREFUWIVjdGEM+c8wgIBpIC0fdcCoA0YdMOoATAcwMjIwcXENkAMYGRneJVgwvFgux8AsLkZ/BzBxcTH8C3rLcMpkKcOXRdx0cwTcAf++fmWQSPvE4HE9kGGvzhq6OQIlDfx5/oKBI/YXXR2BkQvo7Qis2ZCejsBZDqA74laZEgMDIyP9HIDsiPC7HgzrgicwvI+zoLojCJaEf56/YHg+Q5mBleEfw5zGfqo7gqiimG/5SYa4pmKaOIK4uuD/fwah+Sdo4gjiKyMaOYK02pAGjiC9OkZyBAMDA8Of4HcMTJycZDuAkeyOCSMjw7dAMwa+Yw8Y/rx4SbYDWMjW+f8/A9e6kwx/yDYAAgZZi2jUASPRAQC9k36E+oG76gAAAABJRU5ErkJggg==\" y=\"-9.819397\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mdc4ac7327c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"27.167679\" xlink:href=\"#mdc4ac7327c\" y=\"41.819397\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(23.986429 56.417835)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.435536\" xlink:href=\"#mdc4ac7327c\" y=\"41.819397\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 50 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(45.073036 56.417835)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_3\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"me81f8b8ed8\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#me81f8b8ed8\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#me81f8b8ed8\" y=\"35.267076\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(7.2 39.066295)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 41.819397 \r\nL 26.925 10.75654 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 57.987857 41.819397 \r\nL 57.987857 10.75654 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 41.819397 \r\nL 57.987857 41.819397 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 10.75654 \r\nL 57.987857 10.75654 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"patch_7\">\r\n    <path d=\"M 209.543182 41.819397 \r\nL 240.606039 41.819397 \r\nL 240.606039 10.75654 \r\nL 209.543182 10.75654 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p93d5dd75a1)\">\r\n    <image height=\"32\" id=\"image8c630bac47\" transform=\"scale(1 -1)translate(0 -32)\" width=\"32\" x=\"209.543182\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABHNCSVQICAgIfAhkiAAAA51JREFUWIWVl02PFEUYx39V3T09Mz2v7Ozi+hJZw4YQDsaABoGDUQI38WQ0fhCvfghijAcPeDIrFz6BB0m4sISXoIgCCRvIhnUZ3IXdZae6PEzvTHV1Vc/s/zKZ6qfq+de/nuepp8T5I99qtAYhyP2aEAIvtB7bCzG2tdfwrBfmBlzOXYuZZG2Ce+M2adPegCxlOg1c6piq2OPW9zBnuMfcR8p0ZkpddkSmvXlUGYlwoqNJCpU5n2IzcrRr37lNcjIJvjWzb9JraE8qW2jS/BIy0pk2viCyCZl2vqDzEc3GZWHCNHAF435g+AkLAWdnRRmx/RYtey2tMwWywTSpQiVCqBSh0vKjcDmepgpakKQpYqBQ7RpPP2mzevoAqp2AUkMSPpjOXLEwDYlRFqQpaSVg++Qm73zzgJVzbdRcB7Qek7Ad2URMp66UdkHrcSmO7j+he6VOJRhw/strPPyiwWC2BWmaV8K1sOtOKLM3IBECXYlAKTq/3mDl4iKrOy3iY30efd5AzbaLStg7duxsGucjAgCi1UTGMa3Ly/z141E2+3XCo//x+GyTNKnlY6IsOMtUcMyTewY6ChG9A4hqzMzSLVrXY75evM5HF26zeqaLTmqQpsU09ZVxHzmrhowLkdboMEDOziCCgPmfbvLLpU+Zj1/QP7XDk8966FqMGCh31bQVMcddpDMEh2dOf5djJSUijmF3QPvGGsvqOGphm605jU6b1Fe2hiSkZ8dlAWmSy4qYdH6vRIhuG8KQt5b+Ifm9wZkj91k7OeDfjw+i48pYCduhqx64VMj+5xUwGxIpoVpBSEnz7nMebC3SPLFO5f0N1tVBan1BsLmN0Nqvhk8dA7lSXGCs9ShF31i6R/9mj51ByMapV/z9VcLum91indgnirehQyqd1BBRxOGf13h1tUcUKaK3X/LwQm1IwheIZRh1RI5dFwyDAN1M4Nk67/7wB3K5CUD03gaPzyaoTiOvgn03lGSKMwhtlkOqEjotAA5deoS40+Tcwp+EH/TZnq+jA5mfZ8eVJyuKTaltaN75UiK6bfTzFyx8f4+rKx9CT1B9toFQ6ZDEfq5kIbKGZFL7tfebVUxmOoiXW8z99pS0XkXsvB46l7LcuUMFd1teBq2HMdFqDNd8vesssSbpQpYZY+6Xkau78bVu9nm7YBM05k5WwH7R2IuYsI7L+XqySEpn0PmI+FDWek9o20NXbk7lxN6t741ovwdNgsD/tLLx+cgSd00AAAAASUVORK5CYII=\" y=\"-9.819397\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_3\">\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.78586\" xlink:href=\"#mdc4ac7327c\" y=\"41.819397\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(206.60461 56.417835)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.053718\" xlink:href=\"#mdc4ac7327c\" y=\"41.819397\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(227.691218 56.417835)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_4\">\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#me81f8b8ed8\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(196.180682 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#me81f8b8ed8\" y=\"35.267076\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(189.818182 39.066295)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_8\">\r\n    <path d=\"M 209.543182 41.819397 \r\nL 209.543182 10.75654 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path d=\"M 240.606039 41.819397 \r\nL 240.606039 10.75654 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path d=\"M 209.543182 41.819397 \r\nL 240.606039 41.819397 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path d=\"M 209.543182 10.75654 \r\nL 240.606039 10.75654 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_3\">\r\n   <g id=\"patch_12\">\r\n    <path d=\"M 26.925 79.094826 \r\nL 57.987857 79.094826 \r\nL 57.987857 48.031969 \r\nL 26.925 48.031969 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p33367a673f)\">\r\n    <image height=\"32\" id=\"image9d6ffea292\" transform=\"scale(1 -1)translate(0 -32)\" width=\"32\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABHNCSVQICAgIfAhkiAAAAaZJREFUWIXt1ztLw1AYBuD3nIQS4tQKNg6ioAgWyWp/QCc3i6KLXfQHWHTXOorQTUREtA5qodhZBEEQim6CN/Ay1nZQMNpLNI2DUi1Ee0nOqYPfmoS84Tw533dIgAybaGLRZr78P8DfCkBlGSCkOQFExYvMdgceQ37uIURR8SK3KeHEt4UzVUdQnULvwi2MTJZLAKptyNj37UIgFKpLwtXYEp5jLRC8bXwC5OIKjooUhlkCAAiE4qA/AbojQBtlvyQkQEdMobsLxWUDe31JCOTrxzjVC5icDcMdSwEmmw2TwjRhXN9BGtcROB9C1ngpX1RdElYjUdwsDjBbkvLnvqXvIQUfMDg3gws9VxGCpYuKjaikaWhdSyE0P43DAri4IJbdkBDwcmG9FXN08Wsv4OGiajNi7cLagOWdbFzU3o4Zuah7HnDaRUMDiZMuajdg+bR9F/ZGMgdcODIT2nHh2FDaqAt7BqyqThfOj+V1umB2LqjmIr3iAZVltgeTn1xcvhYhJt0o5fMMDFjVNxfRnjgmImF41j8c8AnwWWK7gid/J+TkcRnhO0SUQh0/muIbAAAAAElFTkSuQmCC\" y=\"-47.094826\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_5\">\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"27.167679\" xlink:href=\"#mdc4ac7327c\" y=\"79.094826\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(23.986429 93.693263)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.435536\" xlink:href=\"#mdc4ac7327c\" y=\"79.094826\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(45.073036 93.693263)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_6\">\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#me81f8b8ed8\" y=\"48.274647\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 52.073866)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#me81f8b8ed8\" y=\"72.542504\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(7.2 76.341723)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_13\">\r\n    <path d=\"M 26.925 79.094826 \r\nL 26.925 48.031969 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_14\">\r\n    <path d=\"M 57.987857 79.094826 \r\nL 57.987857 48.031969 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_15\">\r\n    <path d=\"M 26.925 79.094826 \r\nL 57.987857 79.094826 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_16\">\r\n    <path d=\"M 26.925 48.031969 \r\nL 57.987857 48.031969 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_4\">\r\n   <g id=\"patch_17\">\r\n    <path d=\"M 209.543182 79.094826 \r\nL 240.606039 79.094826 \r\nL 240.606039 48.031969 \r\nL 209.543182 48.031969 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p518632228f)\">\r\n    <image height=\"32\" id=\"imagef1b28806be\" transform=\"scale(1 -1)translate(0 -32)\" width=\"32\" x=\"209.543182\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-47.094826\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_7\">\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.78586\" xlink:href=\"#mdc4ac7327c\" y=\"79.094826\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(206.60461 93.693263)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.053718\" xlink:href=\"#mdc4ac7327c\" y=\"79.094826\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(227.691218 93.693263)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_8\">\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#me81f8b8ed8\" y=\"48.274647\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(196.180682 52.073866)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#me81f8b8ed8\" y=\"72.542504\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(189.818182 76.341723)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_18\">\r\n    <path d=\"M 209.543182 79.094826 \r\nL 209.543182 48.031969 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_19\">\r\n    <path d=\"M 240.606039 79.094826 \r\nL 240.606039 48.031969 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_20\">\r\n    <path d=\"M 209.543182 79.094826 \r\nL 240.606039 79.094826 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_21\">\r\n    <path d=\"M 209.543182 48.031969 \r\nL 240.606039 48.031969 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_5\">\r\n   <g id=\"patch_22\">\r\n    <path d=\"M 26.925 116.370254 \r\nL 57.987857 116.370254 \r\nL 57.987857 85.307397 \r\nL 26.925 85.307397 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p4e4d02d7e6)\">\r\n    <image height=\"32\" id=\"imagef0249d0dd3\" transform=\"scale(1 -1)translate(0 -32)\" width=\"32\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABHNCSVQICAgIfAhkiAAAAOBJREFUWIVj/Ptc5T/DAAKmgbR81AGjDhh1wKgDRh0w6oBRB4w6YFA4gIVSA179/crw4i8zipgE818GMWZu+jjAfEshg1bLExSxa7UyDPf9ZtHHAczfmBj+PH2GIsb0Q45o/RSlgb///zEw/WJENZCXl0HT4CF9HHDj908GlbkvUA3k42VoU1hPHwf8/s/EwPj1OyVGDHw2HNoOePWXh+H/v38oYu/s5RgkmP/SxwHpuxIZ/r56jeooMwaiCyGKHcD8nYmB4T9lfVuKCiILyxsMJ3otUMTsLK6SZAbjQHfPASwsOnTwGeHLAAAAAElFTkSuQmCC\" y=\"-84.370254\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_9\">\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"27.167679\" xlink:href=\"#mdc4ac7327c\" y=\"116.370254\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(23.986429 130.968692)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_10\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.435536\" xlink:href=\"#mdc4ac7327c\" y=\"116.370254\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_18\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(45.073036 130.968692)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_10\">\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_19\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#me81f8b8ed8\" y=\"85.550076\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_19\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 89.349295)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_10\">\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#me81f8b8ed8\" y=\"109.817933\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_20\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(7.2 113.617152)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_23\">\r\n    <path d=\"M 26.925 116.370254 \r\nL 26.925 85.307397 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_24\">\r\n    <path d=\"M 57.987857 116.370254 \r\nL 57.987857 85.307397 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_25\">\r\n    <path d=\"M 26.925 116.370254 \r\nL 57.987857 116.370254 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_26\">\r\n    <path d=\"M 26.925 85.307397 \r\nL 57.987857 85.307397 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_6\">\r\n   <g id=\"patch_27\">\r\n    <path d=\"M 209.543182 116.370254 \r\nL 240.606039 116.370254 \r\nL 240.606039 85.307397 \r\nL 209.543182 85.307397 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p2f22cf2ff8)\">\r\n    <image height=\"32\" id=\"imageb062ef8b13\" transform=\"scale(1 -1)translate(0 -32)\" width=\"32\" x=\"209.543182\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-84.370254\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_11\">\r\n    <g id=\"xtick_11\">\r\n     <g id=\"line2d_21\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.78586\" xlink:href=\"#mdc4ac7327c\" y=\"116.370254\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_21\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(206.60461 130.968692)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_12\">\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.053718\" xlink:href=\"#mdc4ac7327c\" y=\"116.370254\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_22\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(227.691218 130.968692)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_12\">\r\n    <g id=\"ytick_11\">\r\n     <g id=\"line2d_23\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#me81f8b8ed8\" y=\"85.550076\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_23\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(196.180682 89.349295)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_12\">\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#me81f8b8ed8\" y=\"109.817933\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_24\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(189.818182 113.617152)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_28\">\r\n    <path d=\"M 209.543182 116.370254 \r\nL 209.543182 85.307397 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_29\">\r\n    <path d=\"M 240.606039 116.370254 \r\nL 240.606039 85.307397 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_30\">\r\n    <path d=\"M 209.543182 116.370254 \r\nL 240.606039 116.370254 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_31\">\r\n    <path d=\"M 209.543182 85.307397 \r\nL 240.606039 85.307397 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_7\">\r\n   <g id=\"patch_32\">\r\n    <path d=\"M 26.925 153.645683 \r\nL 57.987857 153.645683 \r\nL 57.987857 122.582826 \r\nL 26.925 122.582826 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p0aa4cc2014)\">\r\n    <image height=\"32\" id=\"image7180c38491\" transform=\"scale(1 -1)translate(0 -32)\" width=\"32\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABHNCSVQICAgIfAhkiAAAASlJREFUWIXt1r1Lw1AUBfBzk4doS5YgzVBIMkgpGYRCnVyDo5N09k9zzeru5OjmYC24pM1iKe3QNhGMqYOOgu/j2oDkze9yfxxyHqGYrnao8Vh1Lm8ADeDvAER4vxjCarXqAYjQx3xwgKoo9g+wHAfpqAv/5gXY/f7EsAM2cQR3UuLjdS51nxVgex2sejbad2PpGT4AEabXJwiSDNV6vX9AcXkGd1KiTGdKcywAy3GwOBVf0Ut8eLwAImziCMePpVL0bAAR+lj1bBzdPmjNGwFUO88L+I7efZbvPCvANHozABHSURdBkmlHbwTQ7TwLwPY6WPb1Om8O0Hxu2QAi9AGAJXplAEfnjQBv533jzv90hOzFw/snVHnOulwJUG237MuBf/tb3gAUziex7GlCrwzgkQAAAABJRU5ErkJggg==\" y=\"-121.645683\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_13\">\r\n    <g id=\"xtick_13\">\r\n     <g id=\"line2d_25\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"27.167679\" xlink:href=\"#mdc4ac7327c\" y=\"153.645683\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_25\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(23.986429 168.244121)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_14\">\r\n     <g id=\"line2d_26\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.435536\" xlink:href=\"#mdc4ac7327c\" y=\"153.645683\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_26\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(45.073036 168.244121)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_14\">\r\n    <g id=\"ytick_13\">\r\n     <g id=\"line2d_27\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#me81f8b8ed8\" y=\"122.825504\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_27\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 126.624723)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_14\">\r\n     <g id=\"line2d_28\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#me81f8b8ed8\" y=\"147.093362\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_28\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(7.2 150.89258)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_33\">\r\n    <path d=\"M 26.925 153.645683 \r\nL 26.925 122.582826 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_34\">\r\n    <path d=\"M 57.987857 153.645683 \r\nL 57.987857 122.582826 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_35\">\r\n    <path d=\"M 26.925 153.645683 \r\nL 57.987857 153.645683 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_36\">\r\n    <path d=\"M 26.925 122.582826 \r\nL 57.987857 122.582826 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_8\">\r\n   <g id=\"patch_37\">\r\n    <path d=\"M 209.543182 153.645683 \r\nL 240.606039 153.645683 \r\nL 240.606039 122.582826 \r\nL 209.543182 122.582826 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p4fc83079b5)\">\r\n    <image height=\"32\" id=\"image660828e53f\" transform=\"scale(1 -1)translate(0 -32)\" width=\"32\" x=\"209.543182\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABHNCSVQICAgIfAhkiAAAA+1JREFUWIWFl8+LXEUQxz/V83b2xyxJ1l8Ys5ggYoyoK6ugQVDEm17i0bMnwX/Ff8WL6MFTyEFYR8UogokgEV1nFyfJJrvZXzPT5eG97qnu1zM2DPNedVdXfauqv11PNj79XAFEAaU11E2fxc6HZynoiNlPQPxUjtRy8fXeVRAEA1E57D9pFKMgc1SzOcAZHfFmf7u+ccJZQVBSyYwm8Iy9PAqa7pOMXNZEw0kBQb5YtP2fyBo0IdRhvuVgYVRFDxvFHIl9jyG2hpS0lkK65kTTWWSJM+FnnJMZjiU61MXlF+ak0ezpEpk3CAooctQtxxXcCI4fF/ZeVHxXiifLgnBqCqjksT06wbg1aNe5CbiRsvbuDp+9/w2jXjtquQ1XOlYxEpmhlsz8wnG9f0X4+Nk+1+++QHVUMCopt7ggjAakvahYRNJoh1COQTvwxBu7/HH0JLevP0d1qGiHtJ6ylLiIoJDPYhEVClF8bfzuWyOurd/ki582Wd4160rFG3ggQVjihILXUSx16HuDMSi8fvkOX26/yuqtLp0TjcBymo/sqDOIqFTteYTCe3ffs/zXPsO3Ryx1xvz77XkW75nFvo1aHVkEsvBIVmDJZjr9lwmcnHPc/uQcH278wnc3rtDb1in52NwXIqnBgXDU1Pxy8knhN+sr2L8E71z9la++32D1ThPeGQVXcsZRGuHKNBSLN+nw9fvpWeHsa0N+2FnnzK0KN8oM5xEIc+GaTqjYhk3baUgIRaFzCidrSsd5JltrdB/qdH7GpZYDBKgSkpl1zwdRs7l4mHSh8/wB9/tPsTrUaWEVRtEpAfysFBScsJQ8Xoa9l5TjB4ssDaUuynk9xAw+UZfzQEmxEIn9S/DRe1t0dxfonNRs1ypkN6exMVF3OdL4XjKuMF4RLmwO6A8vsnhPYhNSMhKpfc5wsaqDns2XIYzaZTi8oHgVBlvnWTjQiMQazZuUWaPmgczLYnOisPjQM14Rntkc8M/PT9PbJu12S7pBP1psO+RKE3nuOiM4XXX0PtjhwdESvb8FN8oo27Kk6YRbRrMLyZUm8iZivAzDNydcW7/J8Y+P1Wd+XuGWOuCILn2u8gvIOhCq+vSMcPWV3/l68DLdvfQyCcQU2VcyAPkVnDlSqasvFaHZOOsDgoH+nxepfluhd2itpUDjUTRA1BhOakVCBAxSW5DWiYUDxfVXqB5pYtQiDWffHj1r3PJ/EgEC8gKi+PHhQR6FlxRxXvlBpgLOp9HIi1HFfpjEHYh8nzhhUhOjM49+M2Ca579xtOVAyFsJWcxvqar/jwuaCKgz6grOemm/8/KOKPnOs+G0p8fo5XuVml6A/wCtofGRSx5kPQAAAABJRU5ErkJggg==\" y=\"-121.645683\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_15\">\r\n    <g id=\"xtick_15\">\r\n     <g id=\"line2d_29\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.78586\" xlink:href=\"#mdc4ac7327c\" y=\"153.645683\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_29\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(206.60461 168.244121)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_16\">\r\n     <g id=\"line2d_30\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.053718\" xlink:href=\"#mdc4ac7327c\" y=\"153.645683\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_30\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(227.691218 168.244121)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_16\">\r\n    <g id=\"ytick_15\">\r\n     <g id=\"line2d_31\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#me81f8b8ed8\" y=\"122.825504\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_31\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(196.180682 126.624723)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_16\">\r\n     <g id=\"line2d_32\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#me81f8b8ed8\" y=\"147.093362\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_32\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(189.818182 150.89258)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_38\">\r\n    <path d=\"M 209.543182 153.645683 \r\nL 209.543182 122.582826 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_39\">\r\n    <path d=\"M 240.606039 153.645683 \r\nL 240.606039 122.582826 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_40\">\r\n    <path d=\"M 209.543182 153.645683 \r\nL 240.606039 153.645683 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_41\">\r\n    <path d=\"M 209.543182 122.582826 \r\nL 240.606039 122.582826 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_9\">\r\n   <g id=\"patch_42\">\r\n    <path d=\"M 26.925 190.921112 \r\nL 57.987857 190.921112 \r\nL 57.987857 159.858254 \r\nL 26.925 159.858254 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pd6fa7197a1)\">\r\n    <image height=\"32\" id=\"image832dc0c4eb\" transform=\"scale(1 -1)translate(0 -32)\" width=\"32\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABHNCSVQICAgIfAhkiAAAAKtJREFUWIXt1jEKwkAQheF/NgGxSCXZFDYewMLCA1h4BPEwnk5rG8HaRhtFsAmKgslay9rqCDvTvuJ9sMOwMpVZQHGcZrkBDGCAdACuKMgqDyI6gN1iyHy1IfOlDqDpBkadA+LiujR2QB1QrsFJ4DIZ6AB6yz0A53GcpfEE+oCmYfvok93jQyQ/+ZKJkFee9nqjreu3KP96OUAIPI+nj1EiO2AAAxjAAP8MeAGrcCAn8A2VMwAAAABJRU5ErkJggg==\" y=\"-158.921112\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_17\">\r\n    <g id=\"xtick_17\">\r\n     <g id=\"line2d_33\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"27.167679\" xlink:href=\"#mdc4ac7327c\" y=\"190.921112\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_33\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(23.986429 205.519549)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_18\">\r\n     <g id=\"line2d_34\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.435536\" xlink:href=\"#mdc4ac7327c\" y=\"190.921112\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_34\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(45.073036 205.519549)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_18\">\r\n    <g id=\"ytick_17\">\r\n     <g id=\"line2d_35\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#me81f8b8ed8\" y=\"160.100933\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_35\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 163.900152)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_18\">\r\n     <g id=\"line2d_36\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#me81f8b8ed8\" y=\"184.36879\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_36\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(7.2 188.168009)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_43\">\r\n    <path d=\"M 26.925 190.921112 \r\nL 26.925 159.858254 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_44\">\r\n    <path d=\"M 57.987857 190.921112 \r\nL 57.987857 159.858254 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_45\">\r\n    <path d=\"M 26.925 190.921112 \r\nL 57.987857 190.921112 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_46\">\r\n    <path d=\"M 26.925 159.858254 \r\nL 57.987857 159.858254 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_10\">\r\n   <g id=\"patch_47\">\r\n    <path d=\"M 209.543182 190.921112 \r\nL 240.606039 190.921112 \r\nL 240.606039 159.858254 \r\nL 209.543182 159.858254 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p7fcdb390fa)\">\r\n    <image height=\"32\" id=\"image4d07eacf6d\" transform=\"scale(1 -1)translate(0 -32)\" width=\"32\" x=\"209.543182\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-158.921112\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_19\">\r\n    <g id=\"xtick_19\">\r\n     <g id=\"line2d_37\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.78586\" xlink:href=\"#mdc4ac7327c\" y=\"190.921112\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_37\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(206.60461 205.519549)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_20\">\r\n     <g id=\"line2d_38\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.053718\" xlink:href=\"#mdc4ac7327c\" y=\"190.921112\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_38\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(227.691218 205.519549)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_20\">\r\n    <g id=\"ytick_19\">\r\n     <g id=\"line2d_39\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#me81f8b8ed8\" y=\"160.100933\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_39\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(196.180682 163.900152)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_20\">\r\n     <g id=\"line2d_40\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#me81f8b8ed8\" y=\"184.36879\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_40\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(189.818182 188.168009)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_48\">\r\n    <path d=\"M 209.543182 190.921112 \r\nL 209.543182 159.858254 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_49\">\r\n    <path d=\"M 240.606039 190.921112 \r\nL 240.606039 159.858254 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_50\">\r\n    <path d=\"M 209.543182 190.921112 \r\nL 240.606039 190.921112 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_51\">\r\n    <path d=\"M 209.543182 159.858254 \r\nL 240.606039 159.858254 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_11\">\r\n   <g id=\"patch_52\">\r\n    <path d=\"M 26.925 228.19654 \r\nL 57.987857 228.19654 \r\nL 57.987857 197.133683 \r\nL 26.925 197.133683 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pf57fc3cd31)\">\r\n    <image height=\"32\" id=\"image72faf32ffc\" transform=\"scale(1 -1)translate(0 -32)\" width=\"32\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABHNCSVQICAgIfAhkiAAAAZJJREFUWIXtlr9LAlEAx7/vvCAeKHREd01lBJl/QNxeOIZIQRCS0eBsYFNgQksIElFQTRct/SLEMWg/mkUMAsd0yMEDDTJt8SrEvDt9KsF993ufD/e+X3hkiaw0MMRwzE8kBFX/AhzixBAECEEpJOP48Aiv5wI4SgcnwDmdKG3KUGJJONAAnxpDvVo1/I5nAeclEdoFRXo+gecPF6L7YQiKCjSM69WzAC+JqFyO4tF7B192HTRMIOTNwXsW0OEP3nv4sgHQ4DtqhaKlM7ruAAt4dwKEQFuT4bgmPcMBq1fQnJkSSwIAPDcReA7yXcOtCbTAQ/FtzCoqaibL9lfMXUEbuNmZGcXwD/CSiNyOG+kAe7ihgN70nPcEqy9+FE/dEK7YwTsKtJuZq6AyA+tp2wFWG7cuQAj4memBwYHfV9BsemL3DHMjZSxmgnBuVPoK/xFomdnyXhTjtxnUNK2v8G8BjlLUA2/4BMFWPAJBUVFn2PROIfqbkJ+UUJanQFNPTGdmWmBYYf8otQVsAVvAFvhvAl8ea6jzToCklgAAAABJRU5ErkJggg==\" y=\"-196.19654\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_21\">\r\n    <g id=\"xtick_21\">\r\n     <g id=\"line2d_41\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"27.167679\" xlink:href=\"#mdc4ac7327c\" y=\"228.19654\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_41\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(23.986429 242.794978)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_22\">\r\n     <g id=\"line2d_42\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.435536\" xlink:href=\"#mdc4ac7327c\" y=\"228.19654\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_42\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(45.073036 242.794978)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_22\">\r\n    <g id=\"ytick_21\">\r\n     <g id=\"line2d_43\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#me81f8b8ed8\" y=\"197.376362\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_43\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 201.17558)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_22\">\r\n     <g id=\"line2d_44\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#me81f8b8ed8\" y=\"221.644219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_44\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(7.2 225.443437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_53\">\r\n    <path d=\"M 26.925 228.19654 \r\nL 26.925 197.133683 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_54\">\r\n    <path d=\"M 57.987857 228.19654 \r\nL 57.987857 197.133683 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_55\">\r\n    <path d=\"M 26.925 228.19654 \r\nL 57.987857 228.19654 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_56\">\r\n    <path d=\"M 26.925 197.133683 \r\nL 57.987857 197.133683 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_12\">\r\n   <g id=\"patch_57\">\r\n    <path d=\"M 209.543182 228.19654 \r\nL 240.606039 228.19654 \r\nL 240.606039 197.133683 \r\nL 209.543182 197.133683 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pb8bf453525)\">\r\n    <image height=\"32\" id=\"imagec53311d0fa\" transform=\"scale(1 -1)translate(0 -32)\" width=\"32\" x=\"209.543182\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABHNCSVQICAgIfAhkiAAABNpJREFUWIWNl99vFFUUxz/nzmy3tiAlQCqVFpCWXxYNoEFMME0kRkwUgiYmhicT44N/gq8mPPviixoj+mTACImo8cGYaECDIESkCnULlJYQpAVKod2ZOT7M3Jk7P3bjSTa7M7P3fL/3/PjeM/LiyneUxFQVESn9Ts3zIIpAFVWFMIzvi4m/oxBEkO4uCCP0wQNnnSKeiddFCaRG+IhkDhPglFAYxT9MTEQsYGLi+7k10tFJc2AFMxu66JwJWXxmCr03l/OR+x2CyTmwO44clva6YLnohCFiDHPDfVx6o5PFB64xucugXZ1ZdKrWiYkJiEjugXgmz9hGxIlUei+MUzK/sY/xV4Vnt//FrXtd9J5UZPpOClpMp4iAkZgALrgUQmU/ThQsEQ0jiEKCDf2Mve4z8sQof97spf5FDz0nJtAgiDfTxmwSLXpGpLh768cpIKnVWBhcRWNfnSc3Nfh5fC19n9XpPjeBNpvgeaWIlQkYk1Wza5aMFmpBIwgCZNEibj3Xz629c7y07jd+uDpE/4c16r+PoSLlAhXJkxFBwEmBC1j4YwreXEDvP4B6nbvbH+XGnnn2rT/HjxOD9L7fSf30P2C8SnD7LSKIydLiE0VgTNzfVWYjFAToQhPTu4Kbu/q48/IsI/0Nvrm8ieUfdNNxdgw8g/heLnJuTalqDjwmABl4Vb7CEA2CmMTQahqvLKV/5Ao7e65z9PRWBj8PqJ1vgO9nBVf0k2hN+swKWkrAWZQqoL0OIwgjws1rGHuti6d2jtL/0DSHz25j8FBA7cIVENOy2lW1VNDphkUcAlWLbZttGuDigTr7d/yKEeXY18+w4dgsZvx6LDRGSsRb+iwQMnb3RZHRMK72YOMAF9+s8d7zRwA4+vcWVh+fwzQmEw+SKmcq3cUzxLG0JpLC9+2Fu0SDIAbfvIZLbxsO7jjCT3fWc+Kjbaw7MY2MT0K9noFXqGbOp+2CCnJ5IUpCRBDQHF7L2FuGd58+zuEb2xk/NMQj319D785CR609eAG48lq1XAM2j+G6VVw60MH+4VMcPL2HgU8MvecbsboZD0zcz2qK/hMA22puixdbPfmv7x7F9DzM9NblTL0QMLL5Al+e2cbQx0380XHUSAqeRooKhbPAdpcuaJGEqhOBZT1M7l7Oir1XGeme4eS3W9j41QxyeSo5kDJwd2ipimAK7oY7HV7ywuTbCeX240sxu/9lScd9zn46zGPfTaLTt8EzaatVAhWteD/JdYlUYj6Rwvw8XdcXmP5lGTf+WMLKU5fjccr3c8DuzluSqFLBVuQAX3wP1Rq10QnWTC1C7t1HgzAGL/luk3fnPy2j45JMDiaDKuL7iO8hs3Og8fDYzkkqOOnGsoElJzTWjMk6wz5LSBi1OTKmrYIB2TBiyiNWSQ9yc0RUfdqqYuIhI98ubXPcwio7o6gL+QUFIaoYy13nqpprQ0vQJSqtCi55l6gyXzyTO69LTgrRSAsx2VVljP7HqWgtrgF3KHUrvCIN4o5vrcCxy9u0ZGKV80Cxklv2e7vDxo1eoQbciOaH0iLjopxWkagCdwDbtrMqprJwWi2y6Sq+IVWdgiR1UhElN41+6Yx22EFWZMW2zNWCTUcYZpriEEnNvZ/4NxjT8l3AtplVvnbym5t6XeGp0gDH/gMyo5enXNBNUgAAAABJRU5ErkJggg==\" y=\"-196.19654\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_23\">\r\n    <g id=\"xtick_23\">\r\n     <g id=\"line2d_45\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.78586\" xlink:href=\"#mdc4ac7327c\" y=\"228.19654\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_45\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(206.60461 242.794978)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_24\">\r\n     <g id=\"line2d_46\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.053718\" xlink:href=\"#mdc4ac7327c\" y=\"228.19654\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_46\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(227.691218 242.794978)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_24\">\r\n    <g id=\"ytick_23\">\r\n     <g id=\"line2d_47\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#me81f8b8ed8\" y=\"197.376362\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_47\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(196.180682 201.17558)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_24\">\r\n     <g id=\"line2d_48\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#me81f8b8ed8\" y=\"221.644219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_48\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(189.818182 225.443437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_58\">\r\n    <path d=\"M 209.543182 228.19654 \r\nL 209.543182 197.133683 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_59\">\r\n    <path d=\"M 240.606039 228.19654 \r\nL 240.606039 197.133683 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_60\">\r\n    <path d=\"M 209.543182 228.19654 \r\nL 240.606039 228.19654 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_61\">\r\n    <path d=\"M 209.543182 197.133683 \r\nL 240.606039 197.133683 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pf5852f33ca\">\r\n   <rect height=\"31.062857\" width=\"31.062857\" x=\"26.925\" y=\"10.75654\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p93d5dd75a1\">\r\n   <rect height=\"31.062857\" width=\"31.062857\" x=\"209.543182\" y=\"10.75654\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p33367a673f\">\r\n   <rect height=\"31.062857\" width=\"31.062857\" x=\"26.925\" y=\"48.031969\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p518632228f\">\r\n   <rect height=\"31.062857\" width=\"31.062857\" x=\"209.543182\" y=\"48.031969\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p4e4d02d7e6\">\r\n   <rect height=\"31.062857\" width=\"31.062857\" x=\"26.925\" y=\"85.307397\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p2f22cf2ff8\">\r\n   <rect height=\"31.062857\" width=\"31.062857\" x=\"209.543182\" y=\"85.307397\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p0aa4cc2014\">\r\n   <rect height=\"31.062857\" width=\"31.062857\" x=\"26.925\" y=\"122.582826\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p4fc83079b5\">\r\n   <rect height=\"31.062857\" width=\"31.062857\" x=\"209.543182\" y=\"122.582826\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pd6fa7197a1\">\r\n   <rect height=\"31.062857\" width=\"31.062857\" x=\"26.925\" y=\"159.858254\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p7fcdb390fa\">\r\n   <rect height=\"31.062857\" width=\"31.062857\" x=\"209.543182\" y=\"159.858254\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pf57fc3cd31\">\r\n   <rect height=\"31.062857\" width=\"31.062857\" x=\"26.925\" y=\"197.133683\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pb8bf453525\">\r\n   <rect height=\"31.062857\" width=\"31.062857\" x=\"209.543182\" y=\"197.133683\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "### INSPECT RECONSTRUCTIONS\n",
    "# function to create list of images, original beside reconstruction\n",
    "def get_table_of_images(imgs_np_x, imgs_np_r):\n",
    "    \n",
    "    #imgs_np_x for np array of ground truth images\n",
    "    #imgs_np_r for np array of reconstructions\n",
    "\n",
    "    assert len(imgs_np_x) == len(imgs_np_r), \"Different length arrays.\"\n",
    "    img_qty = len(imgs_np_x)\n",
    "    img_lst = []\n",
    "\n",
    "    fig,ax = plt.subplots(img_qty,2)\n",
    "\n",
    "    for i in range(img_qty):\n",
    "        img_x = Image.fromarray(imgs_np_x[i,:,:,0].astype(np.uint8))\n",
    "        ax[i][0].imshow(img_x)\n",
    "        img_r = Image.fromarray(imgs_np_r[i,:,:,0].astype(np.uint8))\n",
    "        ax[i][1].imshow(img_r)\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "mask        = get_batch_mask(testi_cln, batch_size=6)\n",
    "x_test      = testi_ltn[mask,...]\n",
    "y_test_true = testi_cln[mask,...]\n",
    "y_test_pred = decoder(x_test).numpy()\n",
    "\n",
    "# range shift, both y_true and y_pred must be returned to 0-255 range\n",
    "y_test_true = de_range_shift(array_np=y_test_true, mins=mins_img, pk2pk=pk2pk_img)\n",
    "y_test_pred = de_range_shift(array_np=y_test_pred, mins=mins_img, pk2pk=pk2pk_img)\n",
    "\n",
    "# function to display above list of images\n",
    "get_table_of_images(imgs_np_x=y_test_true, imgs_np_r=y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Encoder to Give Latents Required by Decoder\n",
    "\n",
    "We now have a decoder which can take the specification of a line, its minimal representation, and draw the line image. This decoder replicates, in a differentiable manner, the line method of the Image class.\n",
    "\n",
    "Of course, this is the component of the process which we can already do with normal code! Its simply useful that the decoder is differentiable whereas the line class is not.\n",
    "\n",
    "The next step is to create an encoder which can compress any image into the required latents. We can then train this with the loss defined by either:\n",
    "    a: the encoder's latents vs the true latents\n",
    "    b: the autoencoder's output image vs the true input image (where autoencoder = encoder + fixed decoder)\n",
    "\n",
    "We'll select option (b) because (a) is trivial and has been tried before, with limited success. Humans would judge the error not on the latents but on the images reulting from those latents.\n",
    "\n",
    "The decoder will be fixed, ie weights not trainable, during this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We'll need to freeze and unfreeze the weights of each layer in a model\n",
    "\n",
    "def set_model_trainability(model, is_trainable):\n",
    "    # ensure we know what to do with our layers (set trainable = true or false)\n",
    "    assert type(is_trainable)==bool, \"Must state whether model is_trainable or not\"\n",
    "    # Set every layer to be non-trainable:\n",
    "    for layer in model.layers:\n",
    "        layer.trainable=is_trainable\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Epochs & Batches\n",
    "num_epochs = 500\n",
    "batch_size = 100 # save as VAE for similar sample size reasons\n",
    "earlystop  = 30  # epochs without progress which trigger early stopping of training\n",
    "\n",
    "# The optimizer\n",
    "optimizer  = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# instantiate model to be trained\n",
    "encoder = encoder_line(name='encoder_line', params_dict=params_dict_enc)\n",
    "\n",
    "# decoder loss function\n",
    "loss_object = tf.keras.losses.mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model to be trained\n",
    "decoder = decoder_line(name='decoder_line', params_dict=params_dict_dec)\n",
    "\n",
    "decoder.load_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train encoder\n",
    "encoder, _, epoch_losses_enc = train_model( train_encoder = encoder,\n",
    "                                            train_decoder = decoder,\n",
    "                                            model_type    = 'autoencoder',  # CHOICE: encoder, decoder, autoencoder (ie encoder+decoder)\n",
    "                                            train_x       = train_cln, \n",
    "                                            train_y       = None,           # y=x for autoencoder\n",
    "                                            valid_x       = valid_cln,\n",
    "                                            valid_y       = None,           # y=x for autoencoder    \n",
    "                                            batch_size    = batch_size, \n",
    "                                            num_epochs    = num_epochs, \n",
    "                                            optimizer     = optimizer,\n",
    "                                            loss_object   = loss_object,\n",
    "                                            earlystop     = earlystop,\n",
    "                                            is_encoder_trainable = True,    # boolean, fixes weights as appropriate for training\n",
    "                                            is_decoder_trainable = False)   # boolean, fixes weights as appropriate for training\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHART TRAINING HISTORY\n",
    "\n",
    "# save training history to file\n",
    "epoch_losses_enc.to_csv(os.path.join(proj_root, *subfolders, 'encoder_epoch_history.csv'))\n",
    "\n",
    "#plot traniing history\n",
    "(p9.ggplot(data   = epoch_losses_enc,\n",
    "           mapping= p9.aes(x='epoch',\n",
    "                           y='loss'))\n",
    "    + p9.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE MODELS\n",
    "\n",
    "# Save encoder\n",
    "filename = 'encoder'\n",
    "save_model_custom(model_object = encoder,\n",
    "                  filename     = filename)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "7044b324f88c4208d441c8fce3c8f6c454026eeaf7e810a2852062e3590255dc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}